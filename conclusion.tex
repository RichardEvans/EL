\section{Conclusion}\label{conclusion}

The work described here was inspired by Sellars' and Brandom's claim
that material incompatibility is conceptually prior to logical
negation.
\Cathoristic{} is a logic without negation in which you can, nevertheless, make incompatible claims.

\subsection{A ``Simple'' Logic}
\Cathoristic{} is a simple logic of atomic sentences.  It contains no
``complex'' logical connectives.  
By ``complex'', we mean logical
connectives that, like disjunction, generate sentences that can be
satisfied in many different distinct ways.  
Negation, disjunction,
implication, existential quantification all create formulae that can
be satisfied in different ways.  
 Disjunction
fails to be simple because there are two equally simple models of
$\phi \lor \psi$.  Similarly, negation fails to be simple because
there are two equally simple models of $\neg (\phi \land \psi)$.
Conjunction is the \emph{only} connective of propositional logic that
is simple, according to this criterion.

Let us define a logic as ``simple'' if the set of satisfying
models of every sentence has a unique least upper bound. 
We saw in Theorem \ref{theorem:decision} of Section \ref{boundedlattice} that \cathoristic{} is simple, according to this definition.

 We close this paper with a discussion of related work and open
problems.

\subsection{Related work} 

We have defined \cathoristic{} as a multi-modal logic based on
exclusion as a logical primitive and investigated its key properties.
Its formal presentation and development owes much to modal
logic in general, and Hennessy-Milner logic in particular.

\subsubsection{Incompatibility as a Fundamental Semantic Relation}
According to Brandom's, the notion of incompatibility is more than just a pre-logical version of negation. 
It also has a \emph{modal} component:
\begin{quote}
The notion of incompatibility can be thought of as a sort of conceptual vector-product of a \emph{negative} component and a \emph{modal} component. It is \emph{non}-com\emph{possibility}\footnote{\cite{brandom} p.126.}.
\end{quote}
Incompatibility is the fundamental master concept that Brandom uses to make sense of the notion of \emph{object} and \emph{agent}.

First, \emph{object-hood}.
Treating ``$A$ is $\phi$'' and ``$B$ is $\psi$'' as incompatible (where $\phi$ and $\psi$ are incompatible predicates) \emph{just is} what it is to treat $A$ and $B$ as the same object:
\begin{quote}
It is not impossible for two different objects to have incompatible properties - say, being copper and electrically insulating. What is impossible is for \emph{one and the same object} to do so. 
Objects play the conceptual functional role of \emph{units of account for alethic modal incompatibilities}. 
A single object just is what cannot have incompatible properties (at the same time).
\end{quote}
It is only because we are continually resolving incompatibilities that we are able to represent an external (mind-independent) object at all:
\begin{quote}
Shouldering the responsibility of repair and rectification of incompatible commitments is what one has to \emph{do} in order to be taking one's claims to be \emph{about} an objective world
\end{quote}
Second, \emph{agent-hood}.
Just as an object \emph{cannot} have incompatible properties, just so a subject \emph{should not} ascribe incompatible properties to something.
To say that two sentences are incompatible is to say that an agent who holds one \emph{should not} hold the other.
\begin{quote}
Objects play the conceptual functional role of \emph{units of account for alethic modal incompatibilities}. 
It is an essential individuating feature of the metaphysical categorical sortal metaconcept \emph{object} that objects have the metaproperty of \emph{modally} repelling incompatibilities...
And, in a parallel fashion, subjects too are individuated by the way they normatively `repel' incompatible commitments.
It is not impermissible for two different subjects to have incompatible commitments - say, for me to take the coin to be copper and you take it to be an electrical insulator. What is impermissible is for \emph{one and the same subject} to do so. Subjects play the conceptual functional role of \emph{units of account for deontic normative incompatibilities}. 
That is, it is an essential individuating feature of the metaphysical categorical sortal metaconcept \emph{subject} that subjects have the metaproperty of \emph{normatively} repelling incompatibilities. A single subject just is what ought not to have incompatible commitments (at the same time)\footnote{\cite{brandom} p.192.}.
\end{quote}

\martin{The stuff above is really interesting, but doesn't directly relate to the 
main body of the paper.}
\richard{The reason I included it is to strengthen the claim that incompatibility is a fundamental notion: it is according to Hegel/Sellars/Brandom the fundamental master-concept from which objects and agents arise. Do you think we should delete it??}

\NI Sellars and Brandom follow Hegel's \emph{Wissenschaft der Logic}
\cite{HegelGWF:wisdlog} in seeing material incompatibility as a
foundational concept from which even the supposedly primitive ideas of
object and agent can be explicated.  If incompatibility is to fill
this fundamental load-bearing role, we should explore all possible
ways of formalising it.  The tantum operator is the simplest
formalisation we could find in which incompatible propositions can be
expressed.

\subsubsection{Brandom's Incompatibility Semantics}

\NI In \cite{brandom}, Chapter 5, Appendix I, Brandom developed a new
type of semantics, Incompatibility Semantics, that takes material
incompatibility - rather than truth-assignment - as the semantically
primitive notion.

Incompatibility Semantics applies to any language, $\mathcal{L}$,
given as a set of sentences.  Given a predicate $\mathsf{Inc}(X)$ which is true of sets $X \subseteq \mathcal{L}$ that are incompatible, he defines an incompatibility function
$\mathcal{I}$ from subsets of $\mathcal{L}$ to sets of subsets of $\mathcal{L}$:
\[
X \in \mathcal{I}(Y) \text{ iff } \mathsf{Inc}(X \cup Y)
\]
We assume that $\mathcal{I}$ satisfies the
monotonicity requirement (Brandom calls it ``Persistence''):
\[
   \text{If } X \in \mathcal{I}(Y) \text{ and } X \subseteq X' \text{ then } X' \in \mathcal{I}(Y)
\]

\NI Now Brandom defines entailment in terms of the incompatiblity
function. Given a set $X \subseteq \mathcal{L}$ and an individual
sentence $\phi \in \mathcal{L}$:

\[
   X \models \phi\quad \text{ iff }\quad \mathcal{I}(\{\phi\}) \subseteq \mathcal{I}(X)
\]

\NI Now, given material incompatibility (as captured by the
$\mathcal{I}$ function) and entailment, he introduces logical negation
as a \emph{derived} concept via the rule:

\[
   \{\neg \phi\} \in \mathcal{I}(X)\quad \text{ iff }\quad X \models \phi
\]

\NI Brandom goes on to show that the $\neg$ operator, as defined, satisfies
the laws of classical negation.  He also introduces a modal operator,
again defined in terms of material incompatibility, and shows that
this operator satisfies the laws of $S5$.

\Cathoristic{} was inspired by Brandom's vision that material
incompatibility is conceptually prior to logical negation: in other
words, it is possible for a community of language users to make incompatible claims, even if that
language has no explicit logical operators such as negation.  The
language users of this simple language may go on to introduce logical
operators, in order to make certain inferential properties explicit -
but this is an optional further development.  The language before that
addition was already in order as it is.

The approach taken in this paper takes Brandom's original insight in a
different direction.  While Brandom defines an unusual (non
truth-conditional) semantics that applies to any language, we have
defined an unusual logic with a standard (truth-conditional) semantics, and then shown that this logic satisfies the Brandomian connection between incompatibility and entailment.

\subsubsection{Peregrin on Defining Negation In Incompatibility Semantics}\label{peregrin}

In \cite{peregrin}, Peregrin provided a set of general structural rules that any logic must satisfy if it is to connect incompatibility ($\mathsf{Inc}$) and entailment ($\models$) via the Brandomian constraint:
\[
X \models \phi \text{ iff } \mathcal{I}(\{\phi\}) \subseteq \mathcal{I}(X)
\]
The general structural rules are:
\begin{eqnarray*}
(\bot) & & \text{if } \mathsf{Inc}(X) \text{ and } X \subseteq Y \text{ then } \mathsf{Inc}(Y) \\
(\models 1) & & \phi, X \models \phi \\
(\models 2) & & \text{if }X, \phi \models \psi \text{ and } Y \models \phi \text{ then } X, Y \models \psi \\
(\bot \models 2) & & \text{if } X \models \phi \text{ for all } \phi, \text{ then } \mathsf{Inc}(X) \\
(\models \bot 2) & & \text{if } \mathsf{Inc}(Y \cup \{\phi\}) \text{ implies } \mathsf{Inc}(Y \cup X) \text{ for all } Y, \text{ then } X \models \phi
\end{eqnarray*}
Peregrin showed that if a logic satisfied the above laws, then incompatibility and entailment are mutually interdefinable, and the logic satisfies the Brandomian constraint:
\[
X \models \phi \text{ iff } \mathcal{I}(\{\phi\}) \subseteq \mathcal{I}(X)
\]
Next, Peregrin gave a pair of laws for defining negation in terms of $\mathsf{Inc}$ and $\models$\footnote{The converse of $(\neg 2)$ follows from $(\neg 1)$ and the general structural laws above.}:
\begin{eqnarray*}
(\neg 1) & & \mathsf{Inc}(\{\phi, \neg \phi\}) \\
(\neg 2) & & \text{if } \mathsf{Inc}(X, \phi) \text{ then } X \models \neg \phi
\end{eqnarray*}
These laws characterise intuitionistic negation as the \emph{minimal incompatible}\footnote{$\psi$ is the minimal incompatible of $\phi$ iff for all $\xi$, if $\mathsf{Inc}(\{\phi\} \cup \{\xi\})$ then $\xi \models \psi$.}.
Now, in \cite{brandom}, Brandom defined negation slightly differently. He used the rule:
\begin{eqnarray*}
(\neg B) & &\mathsf{Inc}(X, \neg \phi) \text{ iff } X \models \phi
\end{eqnarray*}
Using this stronger rule, we can infer the classical law of double-negation: $\neg \neg \phi \models \phi$.
Peregrin established that Brandom's rule for negation entail $(\neg 1)$ and $(\neg 2)$ above, but not conversely: Brandom's rule is stronger than Peregrin's minimal laws $(\neg 1)$ and $(\neg 2)$.

Peregrin concludes that the Brandomian constraint between incompatibility and entailment is satisfied by many different logics. 
Brandom and Aker happened to choose a particular rule for negation that led to classical logic, but the general connection between incompatibility and entailment is satisfied by many different logics, including intuitionistic logic.
This paper supports Peregrin's conclusion: we have shown that \cathoristic{} also satisfies the Brandomian constraint.

\subsubsection{Peregrin and Turbanti on Defining Necessity In Incompatibility Semantics}\label{peregrin}

In \cite{brandom}, Brandom gave a rule for defining necessity in terms of incompatibility and entailment:
\[
X \in \mathcal{I}(\{\Box \phi\}) \text{ iff } \mathsf{Inc}(X) \lor \exists Y . \; Y \notin \mathcal{I}(X) \land Y \nvDash \phi
\]
In other words, $X$ is incompatible with $\Box \phi$ if $X$ is compatible with something that does not entail $\phi$.

The trouble is, as Peregrin and Turbanti point out, if $\phi$ is not tautological, then \emph{every set} $X \subseteq \mathcal{L}$ is incompatible with $\Box \phi$.
To show this, take any set $X \subseteq \mathcal{L}$. 
If $\mathsf{Inc}(X)$, then $X \in \mathcal{I}(\Box \phi)$ by definition.
If, on the other hand, $\neg \mathsf{Inc}(X)$, then let $Y = \{\}$.
Now $\neg \mathsf{Inc}(X \cup Y)$ as $Y = \{\}$, and $Y \nvDash \phi$ as $\phi$ is not tautological.
Hence $X \in \mathcal{I}(\Box \phi)$ for all $X \subseteq \mathcal{L}$. 
Brandom's rule, then, is only capable of specifying a very specific form of necessity: logical necessity.

In \cite{peregrine} and \cite{turbanti}, Peregrin and Turbanti describe alternative ways of defining necessity.
These alternative rule sets can be used to characterise modal logics other than S5.
For example, Peregrin defines the accessibility relation between worlds in terms of a \emph{compossibility relation}, and then argues that the S4 axiom of transitivity fails because compossibility is not transitive.

We draw two conclusions from this work.
The first is, once again, that a commitment to connecting incompatibility and entailment via the Brandomian constraint:
\[
X \models \phi \text{ iff } \mathcal{I}(\{\phi\}) \subseteq \mathcal{I}(X)
\]
does not commit us to any particular logical system. 
There are a variety of logics that can satisfy this constraint.
Second, questions about the structure of the accessibility relation in Kripke semantics - questions that can seem hopelessly abstract and difficult to answer - can be re-cast in terms of concrete questions about the incompatibility relation.
Incompatibility semantics can shed light on possible-world semantics \cite{turbanti}. 

\subsubsection{Linear logic}

Linear logic \cite{GirardJY:linlog,GirardJY:protyp} is a refinement of
first-order logic and was introduced by J.-Y.~Girard with the aim of
bringing the symmetries of classical logic to constructive
logic. Linear logic has been fruitful in a variety of fields, in
particular in the study of typing systems, where the concept of
linearity puts type-based resource handling on a sound logical basis.

Linear logic splits conjunction into two: additive and multiplicative
conjunction The former, additive conjunction $A \& B$, is especially
interesting in the context of \cathoristic{}. It can be interpreted
\cite{AbramskyS:comintoll} as, in the terminology of process calculus,
an external choice operation. External, because the choice is offered
to the environment.  This interpretation has been influential in the
study of types for process calculus,
e.g.~\cite{HondaK:unitypsfsifLONG,TakeuchiK:intbaslaits,HondaK:lanpriatdfscbp}.
Implicitly, additive conjunction gives an explicit upper bound on how
many different options the environment can choose from. For example in
$A \& B \& C$ we have three options (assuming that none of $A, B, C$
can be decomposed into further additive conjunctions).  With this in
mind, and simplifying a great deal, a key difference between $!A$ and
additive conjunction $A \& B$ is that the individual actions in $!A$
have no continuation, while they do with $A \& B$: $!\{l, r\}$ says
that at this point the only available actions are $l$ and $r$. What
happens at later states is not constraind by $!A$.  In contrast, $A \&
B$ says not only that at this point the only available options are $A$
and $B$, but also that if we choose $A$, then $A$ holds 'for ever',
and likewise for choosing $B$. To be sure, the alternatives in $A \&
B$ may themselves contain further additive conjunctions, and in this
way express how exclusion changes 'over time'.

In summary, \cathoristic{} and linear logic offer  operators that restrict
the available options. How are they related? Linear logic has an
explicit linear negation $(\cdot)^{\bot}$ which, unlike classical
negation, is constructive. In constrast, \cathoristic{} defines a restricted
form negation from $!A$. Can these two perspectives be frutifully
reconciled?

\subsubsection{Process calculus}

Process calculi are models of concurrent computation.  They are based
on the idea of message passing between actors running in parallel.
Labelled transition systems are often used as models for process
calculi, and many concepts used in the development of \cathoristic{},
for example bisimulations and Hennessy-Milner logic, originated in
process theory (although some, such as bisimulation, evolved
independently in other contexts).

Process calculi typically feature a construct called sum, that is an
explicit description of mutually exclusive option:
\[
     \sum_{i \in I} P_i
\]
That is a process that can internally choose, or be chosen to evolve
into the process $P_i$ for each $i$. Once the choice is made, all
other options disappear.  Sums also relate closely to linear logic's
additive conjunction. Is this conceptual proximity a coincidence or
indicative of deeper common structure?


\subsubsection{Failures/divergences in process calculi}

Our cathoristic models are close to a form of the failures/divergences
models that has been used in the denotational semantics of process
calculi, primarily Hoare's CSP \cite{HoareC:comseq,RoscoeAW:theapoc}
and its descendants.  In this model, the denotation of a process $P$
is given as a pair $(traces(P), fail(P))$ where $traces(P) = \{
\sigma\ |\ (\sigma, X) \in \SEMB{P} \}$ are $P$'s traces, and
$fail(P)$ it's failures.  A \emph{failure} is a pair $(\sigma, R)$
where $\sigma \in \Sigma^*$ and $R \subseteq \Sigma$. The intended
interpretation is that a process $P$ has failure $(\sigma, R)$
provided that $\sigma$ is a trace of $P$ and after $P$ executes all
the actions in $\sigma$ it refuses to do any action given in $R$. The
denotation $\SEMB{P}$ of $P$ in a failures/divergences model is the
the set of all of $P$'s failures. The set $ traces(P)$ is
prefix-closed, hence gives rise of a deterministic labelled transition
system: States are given by the set $traces(P)$ of all traces.
Transitions are of the form $\sigma \TRANS{a} \sigma.a$, where
$\sigma.a$ is the string extending $\sigma$ with the action $a$.  The
start state is the empty string.  We can decorate all states as
follows: $ \lambda (\sigma) = \Sigma \setminus R $ provided that
$(\sigma, R) \in \SEMB{P}$.  Whenever the set $\Sigma$ of symbols is
finite, we obtain an cathoristic model this way.

While the failures/divergences semantics of CSP are somewhat more
complicated due to the possibility of diverging programs, the close
connection between cathoristic models and the denotations of CSP processes,
as well as the syntatic similarity with Hennessy-Milner logic suggest
that it might be fruitful to investigate how \cathoristic{} can be used
as a program logic for process calculi.

\subsubsection{Linguistics}

Linguists have also investigated how mutually exclusive alternatives
are expressed, often in the context of antonymy
\cite{OKeeffeA:rouhanocl,AronoffM:hanlin,AllanK:conencos}, but, to the
best of our knowledge have not proposed formal theories of linguistic
exclusion.

\subsection{Open problems} 

The present paper introduced \cathoristic{}, and established key
meta-logical properties such as completeness and compactness. However,
many questions are left open. 

\subsubsection{\Cathoristic{} as a fragment of first- and second-order logic }

A question that has been fruitful in modal logic has been which
fragment of first-order logic corresponds to modal formulae?  Van
Benthem established that modal logic is the fragment of first-order
logic invariant under bisimulation \cite{BlackburnP:modlog}. What is
the the fragment corresponding to \cathoristic{}? Our Theorem
\ref{theorem:completeLattice} suggests to look at closure under mutual
simulation.  

Van Benthem's result was generalised to monadic second
order by Janin and Walukiewicz \cite{JaninD:expcomotpmcwrtmsol} who
showed that the bisimulation invariant fragment of monadic
second-order logic is the modal $\mu$-calculus, an extension of modal
logic with fixpoint operators \cite{KozenD:respromc}.  It would be
interesting to study the \emph{cathoristic $\mu$-calculus}, which adds
fixpoints to \cathoristic{}:
\begin{GRAMMAR}
  \phi
     &::=&
  \TRUE
     \VERTICAL
  \phi \AND \psi
     \VERTICAL
  \MAY{a}\phi
     \VERTICAL
  !A
     \VERTICAL
  \mu \PVAR{x}.\phi
     \VERTICAL
  \nu \PVAR{x}.\phi
     \VERTICAL
  \PVAR{x}
\end{GRAMMAR}

\NI Here $\PVAR{x}$ ranges over propositional variables.  Such a logic
would be useful for talking about infinite transition systems and the
structures of exclusion they give rise to.  For example the phases of
a traffic light can be described as follows.
\[
   \MAY{tl}{\MAY{colour}{\mu \PVAR{x}.
       (!\{green\} \AND \MAY{green}{
         (!\{amber\} \AND \MAY{amber}{
           (!\{red\} \AND \MAY{red}{\PVAR{x}})})})}}
\]

 What properties does the
cathoristic $\mu$-calculus have? In the absence of negation, a lot of proof
techniques taken for granted in the meta-theory of the modal
$\mu$-calculus, such as the relationship between least and greatest
fixpoints, is no longer available.

\subsubsection{Excluded middle}

A better understanding of \cathoristic{}'s relationship with first-order
logic might also lead to insight into excluded middle in \cathoristic{}.
The logical law of excluded middle states that either a proposition or
its negation must be true. In \cathoristic{}
\[
\models \phi \lor \neg_S(\phi)
\]

\NI does not hold in general. (The negation operator $\neg_{S}(\cdot)$
was defined in Section \ref{ELAndNegation}) For example, let $\phi$ be
$\langle a \rangle \top$ and $S = \Sigma = \{a, b\}$.  Then
\[
   \phi \lor \neg_{S} \phi 
       \quad=\quad 
   \langle a \rangle \top \; \lor \; ! \{b\} \; \lor \; \langle a \rangle \bot
\]

\NI Now this will not in general be valid - it will be false for
example in the model $((\{x\}, \emptyset, \{(x, \Sigma)\}), x)$, the
model having just the start state (labelled $\Sigma$) and no transitions.
Restricting $S$ to be a proper subset of $\Sigma = \{a, b\}$ is also not
enough. For example with $S = \{a\}$ we have
\[
   \MAY{a}{\TRUE} \lor \neg_{S}(\MAY{a}{\TRUE})
      \quad=\quad
   \MAY{a}{\TRUE}\ \lor\ !\emptyset \lor \MAY{a}{\FALSE}
\]
This formula cannot hold in any cathoristic model which contains a
$b$-labelled transition, but no $a$-transition from the start state.

Is it possible to identify classes of models that nevertheless verify
excluded middle? The answer to this question appears to depend 
on the chosen notion of semantic model.

\subsubsection{Understanding the expressive strength of \cathoristic{}}

The expressive power of logics can be understood in several different
ways. One gauge of expressivity is to consider embeddings.  We have
already discussed how \cathoristic{} can be embedded into first-order
logic and Hennessy-Milner logic.  A more precise understanding of the
relationship with first-order and second-order logic was already
mentioned as an important open question. But the relationship with
other logics is also interesting, as are other ways of understanding
logical expressivity.  Consider the following six languages:

\input{figure:relationships}

\begin{center}
\begin{tabular}{ l | r }
Language & Description \\
\hline
PL[$\land$] & Propositional logic without negation \\
Hennessy-Milner logic[$\land$] & Hennessy-Milner logic without negation \\
EL[$\land, !$] & \Cathoristic{} restricted to $\land$ and $\fBang$ \\
PL [$\land, \neg$] & Full propositional logic \\
HML [$\land, \neg$] & Full Hennessy-Milner logic \\
EL [$\land, !, \neg$] & Full \cathoristic{} \\
\end{tabular}
\end{center}


\NI The top three languages are simple. In each case: there is no
facility for expressing disjunction, every formula that is satisfiable
has a simplest satisfying model, and there is a simple quadratic-time
decision procedure But there are two ways in which EL[$\land, !$] is
more expressive.  Firstly, EL[$\land, !$], unlike either PL[$\land$]
or HML[$\land$], is expressive enough to be able to distinguish
between any two models that are not bisimilar, cf.~Theorem
\ref{hennessymilnertheorem}\martin{What does it mean for PL to
  distinguish things up to bisimilarity?}.  The second way in which
EL[$\land, !$] is significantly more expressive than both PL[$\land$]
and HML[$\land$] is in its ability to express incompatibility.  No two
formulae of PL[$\land$] or HML[$\land$] are incompatible with each
other\martin{Have we defined incompatibility of PL/HML?}.  But many
pairs of formulae of EL[$\land, !$] are incompatible.  (For example:
$\langle a \rangle \top$ and $! []$).  Because EL[$\land, !$] is
expressive enough to be able to make incompatible claims, it satisfies
Brandom's property of incompatibility semantics, discussed in Section
\ref{incompatibility}:
\[
   p \models q \mbox{ iff } \INC{q} \subseteq \INC{p}
\]

\NI EL[$\land, !$] is the only logic we are aware of with a
quadratic-time decision procedure that is expressive enough to respect
incompatibility semantics. 

The bottom three language can all be decided in exponential time.  We
think that Hennessy-Milner logic is more expressive than PL, and EL
[$\land, !, \neg$] is more expressive than full Hennessy-Milner logic.
To see that full Hennessy-Milner logic is more expressive than full
propositional logic, fix a propositional logic with the nullary
operator $\top$ plus an infinite number of propositional atoms
$P_{(i,j)}$, indexed by $i$ and $j$.  Now translate each formula of
Hennessy-Milner logic via the rules:
\begin{align*}
  \SEMB{\top}  & =  \top  &
  \SEMB{\phi \land \psi} & =  \SEMB{\phi} \land \SEMB{\psi}  \\
  \SEMB{\neg \phi} & =  \neg \SEMB{\phi}   &
  \SEMB{\langle a_i \rangle \phi_j} & =  P_{(i,j)} 
\end{align*}

\NI We think Hennessy-Milner logic is more expressive because there
are formulae $\phi$ and $\psi$ of Hennessy-Milner logic such that
\[
\phi \models_{\text{{HML}}} \psi \mbox{ but } \SEMB{\phi} \nvDash_{\text{PL}} \SEMB{\psi}
\]
For example, let $\phi = \langle a \rangle \langle b \rangle \top$ and
$\psi = \langle a \rangle \top$.  Clearly, $\phi \models_{\text{HML}}
\psi$. But $\SEMB{\phi} = P_{(i,j)}$ and $\SEMB{\psi} = P_{(i',j')}$
for some $i,j,i',j'$, and there are no entailments in propositional
logic between arbitrary propositional atoms.

We close with a hint that may indicate how EL [$\land, !, \neg$] is
more expressive than full Hennessy-Milner logic: the formula $\fBang
A$ of EL can be translated into Hennessy-Milner logic as:
\[
\bigwedge_{a \in \Sigma - A} \neg \langle a \rangle \top
\]
But if $\Sigma$ is infinite, then this is an infinitary disjunction.
\Cathoristic{} can express the same thing in finitary ways.

\subsubsection{Compactness, ultraproducts and \cathoristic{}}

Mathematicals knows three substantially different approaches for
proving compactness: G\"odel's original approach, refined by Morley
and many others, uses proof rules and the completeness theorem.  Our
proof in Section \ref{compactnessProof} works by translation and
piggy-backs on the compactness of first-order logic. Finally, the
model-theoretic approach uses ultra-products as a tool for 'gluing'
together the models that guarantee finite
satisfiability. Ultra-products are quotients of reduced products by an
ultra-filter. The conditions defining ultra-filters are carefully
chosen to ensure that the quotient is indeed an appropriate model with
nice properties such as \L{}o\'{s}' theorem. In particular, for $U$ to
be an ultra-filter over some set $S$, for each $A \subseteq S$, either
$A$ or its complemnet $S\setminus A$ must be in $U$. This axiom
clearly reflects the semantics of negation. But \cathoristic{} doesn't
have negation. So what would an appropriate equivalent of
ultra-filters for \cathoristic{} look like that can be used to prove
compactness directly on models?

\subsubsection{Extending \cathoristic{} with dualities}

Even if not explicitly defined, conventional modal logics have not
just a may modality, but also its dual, the must modality. This is a
direct consequence of the presence of negation: $\MUST{a}{\phi} = \neg
\MAY{a}{\neg \phi}$. In \cathoristic{} the situation is different: since
negation is not available, adding $\MUST{a}{\phi}$ is a substantial
change to the logic: for example the processes in Figure
\ref{figure:counterexample}, indistinguishable by cathoristic formulae, are
separated by
  \[
     \MUST{a}{\MAY{b}{}},
  \]
  assuming the usual semantics: $(\LLL, s) \models \MUST{a}{\phi}$ if
  $s \TRANS{a} t$ implies that $(\LLL, t) \models \phi$. That means
  Theorem \ref{theorem:completeLattice} fails. What notion of model
  equivalence does elementary equivalence become in this scenario?
  What do complete proof rules look like?

  Similar questions can be asked for other additional primitives. If negation is 
  available, the formula
  \[
     \MAY{a}{\neg \MAY{b}{} }
  \]
  separates the afromentioned examples. If we add implication instead,
  negation becomes definable: $\neg \phi = \phi \rightarrow \bot$.




