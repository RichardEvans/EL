\section{Conclusion}\label{conclusion}

\NI We have proposed eremic logic, a modal logic based on the
exclusion as a logical primitive. We have investigated key
meta-theoretic properties of the logic, related eremic logic to
first-order logic and Hennessy-Milner logic, and we have explored
applications in the philosophy of language, knowledge representation
and the semantics of concurrent processes.  

\subsection{Related work} 

Eremic logic emerged out of an engagement with Brandom's
incompatibility semantics.  Its formal presentation and developemnt
owes to modal logic in general and Hennessy-Milner logic in
particular.

\subsubsection{Brandom's Incompatibility Semantics}

The origins of eremic logic lay in classical philosophy, in particular
in Hegel's work on ``bestimmte Negation'' (determinate negation)).  In
his \emph{Wissenschaft der Logic} \cite{HegelGWF:wisdlog}, Hegel
develops the concept that concept, in part in reaction to Kant's use
of material incompatibility in the \emph{Kritik der reinen Vernunft}
\cite{KantI:kdrv}, but also in relation to Spinoza's \emph{omnis
  determinatio est negatio} \cite{???}.  In the twentieth century,
determinate negation has been important in the Neo-Marxist tradition
of the Frankfurt School, in particular in Adorno's negative dialectics
\cite{AdornoTW:negdia}, but also in the .
 analytic tradition. In particular Brandom ...


In \cite{brandom2} and \cite{brandom}, Brandom has emphasised that
logical negation is a degenerate case of material incompatibility:

\begin{quote}
Incompatible sentences are Aristotelian \emph{contraries}. A sentence
and its negation are \emph{contradictories}. What is the relation
between these? Well, the contradictory is a contrary: any sentence is
incompatible with its negation. What distinguishes the contradictory
of a sentence from all the rest of its contraries? The contradictory
is the \emph{minimal} contrary: the one that is entailed by all the
rest. Thus every contrary of ``Plane figure $f$ is a circle'' - for
instance ``$f$ is a triangle'', ``$f$ is an octagon'', and so on -
entails ``$f$ is \emph{not} a circle''.
\end{quote}

\NI In \cite{brandom}, Chapter 5, Appendix I, Brandom developed a new
type of semantics, Incompatibility Semantics, that takes material
incompatibility - rather than truth-assignment - as the semantically
primitive notion.

Incompatibility Semantics applies to any language, $\mathcal{L}$,
given as a set of sentences.  It uses an incompatibility function
$\mathcal{I}$, that, given a set of sentences $S \subseteq
\mathcal{L}$, produces the set of sets of sentences that are
incompatible with $S$.  We assume that $\mathcal{I}$ satisfies the
monotonicity requirement (Brandom calls it ``Persistence''):
\[
   \text{If } X \in \mathcal{I}(Y) \text{ and } X \subseteq X' \text{ then } X' \in \mathcal{I}(Y)
\]

\NI Now Brandom defines entailment in terms of the incompatiblity
function. Given a set $X \subseteq \mathcal{L}$ and an individual
sentence $\phi \in \mathcal{L}$:

\[
   X \models \phi \text{ iff } \mathcal{I}(\{\phi\}) \subseteq \mathcal{I}(X)
\]

\NI Now, given material incompatibility (as captured by the
$\mathcal{I}$ function) and entailment, he introduces logical negation
as a \emph{derived} concept. Using $N \phi$ for the negation of
$\phi$, he introduces negation via the rule:

\[
   \{N \phi\} \in \mathcal{I}(X) \text{ iff } X \models \phi
\]

\NI Brandom goes on to show that the $N$ operator, as defined, satisfies
the laws of classical negation.  He also introduces a modal operator,
again defined in terms of material incompatibility, and shows that
this operator satisfies the laws of $S5$.

\ELFULL{} was inspired by Brandom's vision that material
incompatibility is conceptually prior to logical negation: in other
words, it is possible for a community of language users to deploy a
language including a material incompatibility relation, even if that
language has no explicit logical operators such as negation.  The
language users of this simple language may go on to introduce logical
operators, in order to make certain inferential properties explicit -
but this is an optional further development.  The language before that
addition was already in order as it is.

The approach taken in this paper takes Brandom's original insight in a
different direction.  While Brandom defines an unusual (non
truth-conditional) semantics that applies to any language, we have
defined a unusual logic with a standard (truth-conditional) semantics.

\subsection{Other Related work}

Linguists have also investigated how mutually exclusive alternatives
are expressed \cite{OKeeffeA:rouhanocl}\martin{See John C email for
  more precise reference}, but, to the best of our knowledge have not
proposed formal theories of linguistic exclusion.

Linear logic \cite{GirardJY:linlog,GirardJY:protyp} is a refinement of
first-order logic and was introduced by J.-Y.~Girard with the aim of
bringing the symmetries of classical logic to constructive
logic. Linear logic has been fruitful in a variety of fields, in
particular in the study of typing systems, where the concept of
linearity puts type-based resource handling on a sound logical basis.

Linear logic splits conjunction into two: additive and multiplicative
conjunction The former, additive conjunction $A \& B$, is especially
interesting in the context of \ELFULL{}. It can be interpreted
\cite{AbramskyS:comintoll} as an external choice operation in the
terminology of CSP \cite{HoareC:comseq}. External, because the choice
is offered to the environment.  This interpretation has been
influential in the study of types for process calculus,
e.g.~\cite{HondaK:unitypsfsifLONG,TakeuchiK:intbaslaits,HondaK:lanpriatdfscbp}.
Implicitly, additive conjunction gives an explicit upper bound on how
many different options the environment can choose from. For example in
$A \& B \& C$ we have three options (assuming that none of $A, B, C$
can be decomposed into further additive conjunctions).  With this in
mind, and simplifying a great deal, a key difference between $!A$ and
additive conjunction $A \& B$ is that the individual actions in $!A$
have no continuation, while they do with $A \& B$: $!\{l, r\}$ says
that at this point the only available actions are $l$ and $r$. What
happens at later states is not constraind by $!A$.  In contrast, $A \&
B$ says not only that at this point the only available options are $A$
and $B$, but also that if we choose $A$, then $A$ holds 'for ever',
and likewise for choosing $B$. To be sure, the alternatives in $A \&
B$ may themselves contain further additive conjunctions, and in this
way express how exclusion changes 'over time'.

In summary, \ELABR{} and linear logic offer an operator that restricts
the available options. How are they related? Linear logic has an
explicit linear negation $(\cdot)^{\bot}$ which, unlike classical
negation, is constructive. In constrast, \ELABR{} defines a restricted
form negation from $!A$. Can these two perspectives be frutifully
reconciled?

Another formalism that has a form of explicit description of mutually
exclusive option as a core primitive are process calculi. They are
models of computation based on the idea of message passing between
actors running in parallel. Labelled transition systems are often used
as models for process calculi, and many concepts, for example
bisimulations and Hennessy-Milner logic, used for developing eremic
logic originated from process theory (although some, such as
bisimulation, evolved independently in other contexts).

Process calculi traditionally have sums, which, in their most general
form, are:
\[
     \sum_{i \in I} P_i
\]
That is a process that can internally choose, or be chosen to evolve
into the process $P_i$ for each $i$. Once the choice is made, all
other options disappear.  Usually, so much generality is not
considered. Instead, input-guarded sums are much better behaved (and
strictly less expressive):
  \[
     \sum_{i \in I} x_{i}(v_i)P_i
  \]
This is a process that can receive a message on each channel $x_i$
and, if such a message arrives with payload $y$, evolve into
$P_i{y/v_i}$ which is the process obtained from $P_i$ by substituting
$y$ for the bound variable $v_i$.  An even better behaved process is
obtained if all inputs use the same input channel and we have only
finitely many alternatives:
  \[
     \sum_{i = 1}^n x(v)P_i
  \]
  Simplifying a great deal, this can be seen as a proof for linear
  logic's additive conjunction
  \[
     \&_{i = 1}^n x(v)A_i
  \]
  provided each $P_i$ is a proof of $A_i$.  It is possible to extend
  the Curry-Howard correspondence to (fragments of) linear logic on
  one side and process calculi on the other \cite{GaySJ:typcalosp}.

In this way, process calculi are related to linear logic (by using
formulae as types) and to eremic logic (because processes and eremic
formulae can be modelled by labelled transition systems, and because
eremic logic is close to logics for processes).\martin{rephrase. How
  did process theory influence EL?}

Our eremic models are remarkably close to a form of the
failures/divergences models that has been used in the denotational
semantics of Hoare's CSP \cite{HoareC:comseq,RoscoeAW:theapoc}.  In
this model, the denotation of a process $P$ is given as a pair

\[
   (traces(P), fail(P))
\]

where $traces(P) = \{ \sigma\ |\ (\sigma, X) \in \SEMB{P} \}$ are
$P$'s traces, and $fail(P)$ it's failures.  A \emph{failure} is a pair
$(\sigma, R)$ where $\sigma \in \Sigma^*$ and $R \subseteq
\Sigma$. The intended interpretation is that a process $P$ has failure
$(\sigma, R)$ provided that $\sigma$ is a trace of $P$ and after $P$
executes all the actions in $\sigma$ it refuses to do any action given
in $R$. The denotation $\SEMB{P}$ of $P$ in a failures/divergences
model is the the set of all of $P$'s failures. The set $ traces(P)$ is
prefix-closed, hence gives rise of a deterministic labelled transition
system.
\begin{itemize}

\item States are given by the set $traces(P)$ of all traces.

\item Transitions are of the form $\sigma \TRANS{a} \sigma.a$, where
  $\sigma.a$ is the string extending $\sigma$ with the action $a$.

\item Start state is the empty string.

\end{itemize}
We can decorate all states as follows:
\[
   \lambda (\sigma) = \Sigma \setminus R
\]
provided that $(\sigma, R) \in \SEMB{P}$.  Whenever the set $\Sigma$
of symbols is finite, we obtain an eremic model this way.

While the failures/divergences semantics of CSP are somewhat more
complicated due to the possibility of diverging programs, the close
connection between eremic logic and the denotation semantics, as well
as the syntatic similarity with Hennessy-Milner logic suggest that it
might be fruitful to investigate how eremic logic can be used as a
program logic for process calculi.

\subsection{Open problems} 

We conclude this paper with a discussion of open problems.

\subsubsection{Eremic logic as a fragment of first- and second-order logic }

A question that has been fruitful in modal logic has been which
fragment of first-order logic corresponds to modal formulae?  Van
Benthem established that modal logic is the fragment of first-order
logic invariant under bisimulation \cite{BlackburnP:modlog}. What is
the the fragment corresponding to eremic logic? Our Theorem
\ref{theorem:completeLattice} suggests to look at closure under mutual
simulation.  

Van Benthem's result was generalised to monadic second
order by Janin and Walukiewicz \cite{JaninD:expcomotpmcwrtmsol} who
showed that the bisimulation invariant fragment of monadic
second-order logic is the modal $\mu$-calculus, an extension of modal
logic with fixpoint operators \cite{KozenD:respromc}.  It would be
interesting to study the \emph{eremic $\mu$-calculus}, which adds
fixpoints to eremic logic:
\begin{GRAMMAR}
  \phi
     &::=&
  \TRUE
     \VERTICAL
  \phi \AND \psi
     \VERTICAL
  \MAY{a}\phi
     \VERTICAL
  !A
     \VERTICAL
  \mu \PVAR{x}.\phi
     \VERTICAL
  \nu \PVAR{x}.\phi
     \VERTICAL
  \PVAR{x}
\end{GRAMMAR}

\NI Here $\PVAR{x}$ ranges over propositional variables.  Such a logic
would be useful for talking about infinite transition systems and the
structures of exclusion they give rise to.  What properties does the
eremic $\mu$-calculus have? In the absence of negation, a lot of proof
techniques taken for granted in the meta-theory of the modal
$\mu$-calculus, such as the relationship between least and greatest
fixpoints, is no longer available.

\subsubsection{Excluded middle}

A better understanding of eremic logic's relationship with first-order
logic might also lead to insight into excluded middle in eremic logic.
The logical law of excluded middle states that either a proposition or
its negation must be true. In eremic logic
\[
\models \phi \lor \neg_S(\phi)
\]

\NI does not hold in general. (The negation operator $\neg_{S}(\cdot)$
was defined in Section \ref{ELAndNegation}) For example, let $\phi$ be
$\langle a \rangle \top$ and $S = \Sigma = \{a, b\}$.  Then
\[
   \phi \lor \neg_{S} \phi 
       \quad=\quad 
   \langle a \rangle \top \; \lor \; ! \{b\} \; \lor \; \langle a \rangle \bot
\]

\NI Now this will not in general be valid - it will be false for
example in the model $((\{x\}, \emptyset, \{(x, \Sigma)\}), x)$, the
model having just the root node (labelled $\Sigma$) and no transitions.
Restricting $S$ to be a proper subset of $\Sigma = \{a, b\}$ is also not
enough. For example with $S = \{a\}$ we have
\[
   \MAY{a}{\TRUE} \lor \neg_{S}(\MAY{a}{\TRUE})
      \quad=\quad
   \MAY{a}{\TRUE}\ \lor\ !\emptyset \lor \MAY{a}{\FALSE}
\]
This formula cannot hold in any eremic model which contains a
$b$-labelled transition, but no $a$-transition from the root.

Is it possible to identify classes of models that nevertheless verify
excluded middle? The answer to this question appears to depend 
on the chosen notion of semantic model.

\subsubsection{Understanding the expressive strength of eremic logic}

The expressive power of logics can be understood in several different
ways. One gauge of expressivity is to consider embeddings.  We have
already discussed how eremic logic can be embedded into first-order
logic and Hennessy-Milner logic.  A more precise understanding of the
relationship with first-order and second-order logic was already
mentioned as an important open question. But the relationship with
other logics is also interesting, as are other ways of understanding
logical expressivity.  Consider the following six languages:

\input{figure:relationships}

\begin{center}
\begin{tabular}{ l | r }
Language & Description \\
\hline
PL[$\land$] & Propositional logic without negation \\
Hennessy-Milner logic[$\land$] & Hennessy-Milner logic without negation \\
EL[$\land, !$] & Eremic logic restricted to $\land$ and $\fBang$ \\
PL [$\land, \neg$] & Full propositional logic \\
HML [$\land, \neg$] & Full Hennessy-Milner logic \\
EL [$\land, !, \neg$] & Full eremic logic \\
\end{tabular}
\end{center}


\NI The top three languages are simple. In each case: there is no
facility for expressing disjunction, every formula that is satisfiable
has a simplest satisfying model, and there is a simple linear-time
decision procedure But there are two ways in which EL[$\land, !$] is
more expressive.  Firstly, EL[$\land, !$], unlike either PL[$\land$]
or HML[$\land$], is expressive enough to be able to distinguish
between any two models that are not bisimilar, cf.~Theorem
\ref{hennessymilnertheorem}\martin{What does it mean for PL to
  distinguish things up to bisimilarity?}.  The second way in which
EL[$\land, !$] is significantly more expressive than both PL[$\land$]
and HML[$\land$] is in its ability to express incompatibility.  No two
formulae of PL[$\land$] or HML[$\land$] are incompatible with each
other\martin{Have we defined incompatibility of PL/HML?}.  But many
pairs of formulae of EL[$\land, !$] are incompatible.  (For example:
$\langle a \rangle \top$ and $! []$).  Because EL[$\land, !$] is
expressive enough to be able to make incompatible claims, it satisfies
Brandom's property of incompatibility semantics, discussed in Section
\ref{incompatibility}:
\[
   p \models q \mbox{ iff } \INC{q} \subseteq \INC{p}
\]

\NI EL[$\land, !$] is the only logic we are aware of with a
linear-time decision procedure that is expressive enough to respect
incompatibility semantics. 

The bottom three language can all be decided in exponential time.  We
think that Hennessy-Milner logic is more expressive than PL, and EL
[$\land, !, \neg$] is more expressive than full Hennessy-Milner logic.
To see that full Hennessy-Milner logic is more expressive than full
propositional logic, fix a propositional logic with the nullary
operator $\top$ plus an infinite number of propositional atoms
$P_{(i,j)}$, indexed by $i$ and $j$.  Now translate each formula of
Hennessy-Milner logic via the rules:
\begin{align*}
  \SEMB{\top}  & =  \top  &
  \SEMB{\phi \land \psi} & =  \SEMB{\phi} \land \SEMB{\psi}  \\
  \SEMB{\neg \phi} & =  \neg \SEMB{\phi}   &
  \SEMB{\langle a_i \rangle \phi_j} & =  P_{(i,j)} 
\end{align*}

\NI We think Hennessy-Milner logic is more expressive because there
are formulae $\phi$ and $\psi$ of Hennessy-Milner logic such that
\[
\phi \models_{\text{{HML}}} \psi \mbox{ but } \SEMB{\phi} \nvDash_{\text{PL}} \SEMB{\psi}
\]
For example, let $\phi = \langle a \rangle \langle b \rangle \top$ and
$\psi = \langle a \rangle \top$.  Clearly, $\phi \models_{\text{HML}}
\psi$. But $\SEMB{\phi} = P_{(i,j)}$ and $\SEMB{\psi} = P_{(i',j')}$
for some $i,j,i',j'$, and there are no entailments in propositional
logic between arbitrary propositional atoms.

We close with a hint that may indicate how EL [$\land, !, \neg$] is
more expressive than full Hennessy-Milner logic: the formula $\fBang
A$ of EL can be translated into Hennessy-Milner logic as:
\[
\bigwedge_{a \in \Sigma - A} \neg \langle a \rangle \top
\]
But if $\Sigma$ is infinite, then this is an infinitary disjunction.
Eremic logic can express the same thing in finitary ways.

\subsubsection{Compactness, ultraproducts and eremic logic}

Another interesting open question is to do with
ultra-products. Mathematical logic knows three substantially different
approaches towards proving compactness: G\"odel's original approach,
refined by Morley and many others, uses proof rules and the
completeness theorem. It thus mixes syntax and semantics. Our proof in
Section \ref{compactnessProof} exemplifies the second approach: proof
by translation that piggy-backs on the compactness of other
logics. Finally, the model-theoretic approach uses ultra-products as a
tool for 'gluing' together the models that guarantee finite
satisfiability. Ultra-products are quotients of reduced products by an
ultra-filter. The conditions defining ultra-filters are carefully
chosen to ensure that the quotient is indeed an appropriate model with
nice properties such as \L{}o\'{s}' theorem. In particular, for $U$ to
be an ultra-filter over some set $S$, for each $A \subseteq S$, either
$A$ or its complemnet $S\setminus A$ must be in $U$. This axiom
clearly reflects the semantics of negation. But eremic logic doesn't
have negation. So what would an appropriate equivalent of
ultra-filters for eremic logic look like that can be used to prove
compactness directly on models?

\subsubsection{Extending eremic logic with dualities}

Even if not explicitly defined, conventional modal logics have not
just a may modality, but also its dual, the must modality. This is a
direct consequence of the presence of negation: $\MUST{a}{\phi} = \neg
\MAY{a}{\neg \phi}$. In eremic logic the situation is different: since
negation is not available, adding $\MUST{a}{\phi}$ is a substantial
change to the logic: for example the processes in Figure
\ref{figure:counterexample}, indistinguishable by eremic formulae, are
separated by
  \[
     \MUST{a}{\MAY{b}{}},
  \]
  assuming the usual semantics: $(\LLL, s) \models \MUST{a}{\phi}$ if
  $s \TRANS{a} t$ implies that $(\LLL, t) \models \phi$. That means
  Theorem \ref{theorem:completeLattice} fails. What notion of model
  equivalence does elementary equivalence become in this scenario?
  What do complete proof rules look like?

  Similar questions can be asked for other additional primitives. If negation is 
  available, the formula
  \[
     \MAY{a}{\neg \MAY{b}{} }
  \]
  separates the afromentioned examples. If we add implication instead,
  negation becomes definable: $\neg \phi = \phi \rightarrow \bot$.




