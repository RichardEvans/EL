\section{Alternative semantics for eremic logic}\label{pureModels}

\martin{Integrate in appendix}

In Section \ref{coreEL} we used node-labelled transition systems as
models for eremic logic. The purpose of the node labels was to express
constrains, if any, on outgoing actions. This concern is reflected in
the semantics of $!A$.
\[
\begin{array}{lclcl}
  ((S, \rightarrow, \lambda), s) & \models & !A  &\mbox{\quad iff\quad } & \lambda(s) \subseteq A
\end{array}
\]

\NI There is an alternative, and in some sense even simpler approach
to giving semantics to $!A$ which does not require a node-labelling:
we simply check if all actions of all outgoing transitions are in $A$.
As no other formula requires the labelling function $\lambda$ in the
definition of it's satisfaction condition, this approach means we can
use plain labelled transition systems (together with a current state)
as models. This gives rise to a subtly different theory that we now
explore, albeit not in depth.

\begin{definition}
By a \emph{pure eremic model}, ranged over by $\PPP, \PPP', ...$, we
mean a pair $(\LLL, s)$ where $\LLL = (S, \rightarrow)$ is a labelled
transition system and $s \in S$ a state.
\end{definition}

\NI Adapting the satisfaction relation to pure eremic models is
straightfoward.

\begin{definition}
Using pure eremic models, the  \emph{satisfaction relation} is defined 
inductively by the following clauses, where we assume that $\MMM =
(\LLL, s)$ and $\LLL = (S, \rightarrow)$.

\[
\begin{array}{lclcl}
  \MMM & \models & \top   \\
  \MMM & \models & \phi \AND \psi &\ \mbox{ iff } \ & \MMM  \models \phi \mbox { and } \MMM \models \psi  \\
  \MMM & \models & \langle a \rangle \phi & \mbox{ iff } & \text{there is a } s \xrightarrow{a} t \mbox { such that } (\LLL, t) \models \phi  \\
  \MMM & \models & A &\mbox{ iff } & \{a\ |\ \exists t.s \TRANS{a} t \} \subseteq A
\end{array}
\]
\end{definition}

\NI Note that all but the last clause are unchanged from Definition
\ref{ELsatisfaction}.

In this interpretation, $!A$ restricts the out-degree of the current
state $s$, i.e.~it constraints the 'width' of the graph.  It is easy
to see that all rules in Figure \ref{figure:elAndBangRules} are sound
with respect to the new semantics too\martin{what about
  completeness?}.  The key advantage pure eremic models have is their
simplicity: they are unadorned labelled transition systems, the key
model of concurrency theory \cite{SassoneV:modcontac}. The connection
with concurrency theory is even stronger than that, because, as we
show below (Theorem \ref{hennessymilnertheorem}), the elementary
equivalence on (finitely branching) pure eremic models is
bisimilarity, one of the more widely used notions of process
equivalence.

This then leads to the question why we most of our development is
about eremic models. The reason is one of philosophy: on pure eremic
models, eremic logic can distinguish models based on branching
structure, for example those in Figure
\ref{figure:counterexample}. However, eremic logic speaks about
exclusion. Prima facie, branching structure has nothing to do with
exclusion. Therefore eremic logic should not distinguish models such
as those just mentioned.

Nevertheless, both kinds of models are compelling, and it is
interesting to see if they can be related in a systematic way.

\subsection{Relationship between pure and eremic models}

The obvious way of converting an eremic model into a pure eremic model
is by forgetting about the node-labelling:
\[
   ((S, \rightarrow, \lambda), s ) \qquad\mapsto\qquad ((S, \rightarrow), s ) 
\]
Let this function be $\FORGET{\cdot}$. For going the other way, we
have two obvious choices:

\begin{itemize}

\item $((S, \rightarrow), s ) \mapsto ((S, \rightarrow, \lambda), s )$
  where $\lambda(t) = \Sigma$ for all states $t$. Call this map $\MAX{\cdot}$.

\item $((S, \rightarrow), s ) \mapsto ((S, \rightarrow, \lambda), s )$
  where $\lambda(t) = \{a \ |\ \exists t'. t \TRANS{a} t'\}$ for all
  states $t$. Call this map $\MIN{\cdot}$.

\end{itemize}

\begin{lemma}\label{modelRelationships}
Let $\MMM$ be an eremic model, and $\PPP$ a pure eremic model.
\begin{enumerate}

\item\label{modelRelationships:1}  $\MMM \models \phi$ implies
  $\FORGET{\MMM} \models \phi$. The reverse implication does not hold.

\item\label{modelRelationships:2}  $ \MAX{\PPP} \models \phi$ implies
  $\PPP \models \phi$. The reverse implication does not hold.

\item\label{modelRelationships:3} $\MIN{\PPP} \models \phi$ if and only if
  $\PPP \models \phi$. 

\end{enumerate}
\end{lemma}

\begin{proof}
The implication in (\ref{modelRelationships:1}) is immediate by
induction on $\phi$. A counterexample for the reverse implication is
given by the formula $\phi = !\{a\}$ and the eremic model $\MMM = ( \{s,
t\}, s \TRANS{a} t, \lambda), s)$ where $\lambda (s) = \{a, b, c\}$:
clearly $\FORGET{\MMM} \models \phi$, but $\MMM \not\models
\phi$.

The implication in (\ref{modelRelationships:2}) is immediate by
induction on $\phi$. To construct a counterexample for the reverse
implication, assume that $\Sigma$ is a strict superset of $\{a\}$
$a$. The formula $\phi = !\{a\}$ and the pure eremic model $\PPP = (
\{s, t\}, s \TRANS{a} t ), s)$ satisfy $\PPP \models \phi$, but clealy
$\MAX{\PPP} \not\models \phi$.

Finally, (\ref{modelRelationships:3}) is also straightforward by
induction on $\phi$.

\end{proof}


\subsection{A semantic characterisation of elementary equivalence for pure eremic models}

In Section \ref{elementaryEquivalence} we presented a semantic
analysis of elementary equivalence, culminating in Theorem
\ref{theorem:completeLattice} which showed that elementary equivalence
coincides with $\MODELEQ$, the relation of mutual simulation of
models. We shall now carry out a similar analysis for pure eremic
models, and show that elementary equivalence coincides with
bisimilarity, an important concept in process theory and modal logics
\cite{SangiorgiD:intbisac}. Bisimilarity is strictly finer than
$\MODELEQ$, and more sensitive to branching structure.  Before stating
and proving the theorem, we need to make precise the used concepts.

\begin{definition}
A pure eremic model $(\LLL, s)$ is finitely branching if its
underlying transition system $\LLL$ is finitely branching.
\end{definition}

\begin{definition}
A binay relation $\RRR$ is a \emph{bisimulation} between pure eremic
models $\PPP_i = (\LLL_i), s_i)$ for $i = 1, 2$ provided (1) $\RRR$ is
a bisimulation between $\LLL_1$ and $\LLL_2$, and (2) $(s_1, s_2) \in
\RRR$. We say $\PPP_1$ and $\PPP_2$ are \emph{bisimilar}, written
$\PPP_1 \BISIM \PPP_2$ if there is a bisimulation between $\PPP_1$ and
$\PPP_2$.
\end{definition}

\begin{definition}
The \emph{theory} of $\PPP$, written $\THEORY{\PPP}$, is the set
$\{\phi\ |\ \PPP \models \phi\}$.
\end{definition}

\begin{theorem}[Hennessy, Milner \cite{HennessyM:alglawfndac}]
\label{hennessymilnertheorem}
Let $\PPP$ and $\PPP'$ be two finitely branching pure eremic
models. Then: $\PPP \BISIM \PPP'$ if and only if $\THEORY{\PPP} =
\THEORY{\PPP'}$.  \martin{discuss the case of non-finitely-branching}
\end{theorem}

\begin{proof}
\NI Let $\PPP = (\LLL, w)$ and $\PPP' = (\LLL', w')$ be finitely
branching, where $\LLL = (W, \rightarrow)$ and $(W', \rightarrow')$.
We first show the left to right direction, so assume that $\PPP \BISIM
\PPP'$.

The proof is by induction on formulae.  The only case which differs
from the standard Hennessy-Milner theorem is the case for $!A$, so
this is the only case we shall consider.  Assume $w \BISIM w'$ and $w
\models !A$. We need to show $w' \models !A$.
From the semantic clause for $!$, $w \models !A$ implies $\lambda(w)
\subseteq A$.  If $w \BISIM w'$, then $\lambda(w) = \lambda'(w')$.
Therefore $\lambda'(w') \subseteq A$, and hence $w' \models !A$.

The proof for the other direction is more involved.
For states $x \in W$ and $x' \in W$, we write 
\[
   x \equiv x'
      \qquad\text{iff}\qquad
   \THEORY{(\LLL, x)} = \THEORY{(\LLL', x')}.
\]

We define the bisimilarity relation:
\[
   Z = \{(x,x') \in \mathcal{W} \times \mathcal{W}' \fOr x \equiv x' \}
\]
To prove $w \BISIM w'$, we need to show:
\begin{itemize}

\item $(w,w') \in Z$. This is immediate from the definition of Z.

\item The relation $Z$ respects the transition-restrictions: if
  $(x,x') \in Z$ then $\lambda(x) = \lambda'(x')$

\item The forth condition: if $(x,x') \in Z$ and $x \xrightarrow{a}
  y$, then there exists a $y'$ such that $x' \xrightarrow{a} y'$ and $(y, y') \in Z$.

\item The back condition: if $(x,x') \in Z$ and $x' \xrightarrow{a}
  y'$, then there exists a $y$ such that $x \xrightarrow{a} y$ and $(y, y') \in Z$.

\end{itemize}
To show that $(x,x') \in Z$ implies $\lambda(x) = \lambda'(x')$, we
will argue by contraposition.  Assume $\lambda(x) \neq \lambda'(x')$.
Then either $\lambda'(x') \nsubseteq \lambda(x)$ or $\lambda(x)
\nsubseteq \lambda'(x')$.  If $\lambda'(x') \nsubseteq \lambda(x)$,
then $x' \nvDash \fBang \lambda(x)$.  But $x \models \fBang
\lambda(x)$, so $x$ and $x'$ satisfy different sets of propositions
and are not equivalent.  Similarly, if $\lambda(x) \nsubseteq
\lambda'(x')$ then $x \nvDash \fBang \lambda'(x')$.  But $x' \models
\fBang \lambda'(x')$, so again $x$ and $x'$ satisfy different sets of
propositions and are not equivalent.

We will show the forth condition in detail. The back condition is very
similar.  To show the forth condition, assume that $x \xrightarrow{a}
y$ and that $(x,x') \in Z$ (i.e. $x \equiv x'$).  We need to show that
$\exists y'$ such that $x' \xrightarrow{a} y'$ and $(y,y') \in Z$
(i.e. $y \equiv y'$).

Consider the set of $y'_i$ such that $x' \xrightarrow{a} y'_i$. Since
$x \xrightarrow{a} y$, $x \models \langle a \rangle \top$, and as $x
\equiv x'$, $x' \models \langle a \rangle \top$, so we know this set
is non-empty.  Further, since $(\mathcal{W}', \rightarrow')$ is
finitely-branching, there is only a finite set of such $y'_i$, so we
can list them $y'_1, ..., y'_n$, where $n >= 1$.

Now, in the Hennessy-Milner theorem for HML, the proof proceeds as
follows: assume, for reductio, that of the $y'_1, ..., y'_n$, there is
no $y'_i$ such that $y \equiv y'_i$.  Then, by the definition of
$\equiv$, there must be formulae $\phi_1, ..., \phi_n$ such that for
all $i$ in $1$ to $n$:
\[
y'_i \models \phi_i \mbox{ and } y \nvDash \phi_i
\]
Now consider the formula:
\[
[a] (\phi_1 \lor ... \lor \phi_n)
\]
As each $y'_i \models \phi_i$, $x' \models [a] (\phi_1 \lor ... \lor \phi_n)$, but $x$ does not satisfy this formula, as each $\phi_i$ is not satisfied at $y$.
Since there is a formula which $x$ and $x'$ do not agree on, $x$ and $x'$ are not equivalent, contradicting our initial assumption.

But this proof cannot be used in \ELABR{} because it relies on a formula $[a] (\phi_1 \lor ... \lor \phi_n)$ which cannot be expressed in \ELABR{}: 
\ELABR{} does not include the box operator or disjunction, so this formula is ruled out on two accounts.
But we can massage it into a form which is more amenable to \ELABR{}'s expressive resources:
\begin{eqnarray*}
[a] (\phi_1 \lor ... \lor \phi_n) & = & \neg \langle a \rangle \neg (\phi_1 \lor ... \lor \phi_n)  \\
	& = & \neg \langle a \rangle (\neg \phi_1\AND ... \AND \neg \phi_n) 
\end{eqnarray*}
Further, if the original formula $[a] (\phi_1 \lor ... \lor \phi_n)$ is true in $x'$ but not in $x$, then its negation will be true in $x$ but not in $x'$. 
So we have the following formula, true in $x$ but not in $x'$:
\[
 \langle a \rangle (\neg \phi_1\AND ... \AND \neg \phi_n)
 \]
The reason for massaging the formula in this way is so we can express it in \ELABR{} (which does not have the box operator or disjunction).
At this moment, the revised formula is \emph{still} outside \ELABR{} because it uses negation. 
But we are almost there: the remaining negation is in innermost scope, and innermost scope negation can be simulated in \ELABR{} by the $!$ operator. 

We are assuming, for reductio, that of the $y'_1, ..., y'_n$, there is no $y'_i$ such that $y \equiv y'_i$.
But in \ELABR{} without negation, we cannot assume that each $y'_i$ has a formula $\phi_i$ which is satisfied by $y'_i$ but not by $y$ - it might instead be the other way round: $\phi_i$ may be satisfied by $y$ but not by $y'_i$. So, without loss of generality, assume that $y'_1, ..., y'_m$ fail to satisfy formulae $\phi_1, ..., \phi_m$ which $y$ does satisfy, and that $y'_{m+1}, ..., y'_n$ satisfy formulae $\phi_{m+1}, ..., \phi_n$ which $y$ does not:
\begin{eqnarray*}
y \models \phi_i \mbox{ and } y'_i \nvDash \phi_i & & i = 1 \mbox{ to } m  \\
y \nvDash \phi_j \mbox{ and } y'_j \models \phi_j & & j = m+1 \mbox{ to } n 
\end{eqnarray*}
The formula we will use to distinguish between $x$ and $x'$ is:
\[
 \langle a \rangle ( \bigwedge_{i=1}^m \phi_i \; \AND \; \bigwedge_{j=m+1}^n \mathsf{neg}(y, \phi_j))
 \]
 Here, $\mathsf{neg}$ is a meta-language function that, given a state y and a formula $\phi_j$, returns a formula that is true in $y$ but incompatible with $\phi_j$. We will show that, since $y \nvDash \phi_j$, it is always possible to construct $ \mathsf{neg}(y, \phi_j)$ using the $!$ operator.

Consider the possible forms of $\phi_j$:
\begin{itemize}
\item
$\top$: this case cannot occur since all models satisfy $\top$.
\item
$\phi_1 \AND \phi_2$: we know $y'_j \models \phi_1 \AND \phi_2$ and $y \nvDash \phi_1 \AND \phi_2$. There are three possibilities:
\begin{enumerate}
\item
$y \nvDash \phi_1$ and $y \models \phi_2$. In this case, $\mathsf{neg}(y, \phi_1 \AND \phi_2) = \mathsf{neg}(y, \phi_1) \AND \phi_2$.
\item
$y \models \phi_1$ and $y \nvDash \phi_2$. In this case, $\mathsf{neg}(y, \phi_1 \AND \phi_2) = \phi_1 \AND \mathsf{neg}(y, \phi_2)$.
\item
$y \nvDash \phi_1$ and $y \nvDash \phi_2$. In this case, $\mathsf{neg}(y, \phi_1 \AND \phi_2) =  \mathsf{neg}(y, \phi_1) \AND \mathsf{neg}(y, \phi_2)$.
\end{enumerate}
\item
$!A$: if $y \nvDash !A \mbox{ and } y'_j \models !A$, then there is a symbol $a \in \Sigma-A$ such that $y \xrightarrow{a} z$ for some $z$ but there is no such $z$ such that $y'_j \xrightarrow{a} z$. In this case, let $\mathsf{neg}(y, \phi_j) = \langle a \rangle \top$.
\item
$\langle a \rangle \phi$. There are two possibilities:
\begin{enumerate}
\item
$y \models \langle a \rangle \top$. In this case, $\mathsf{neg}(y, \langle a \rangle \phi) =  \bigwedge\limits_{y \xrightarrow{a} z}  \langle a \rangle \mathsf{neg}(z, \phi)$.
\item
$y \nvDash \langle a \rangle \top$. In this case, $\mathsf{neg}(y, \langle a \rangle \phi) = \fBang \{ b \fOr \exists z. y \xrightarrow{b} z\}$. This set of $b$s is finite since we are assuming the LTS is finitely-branching.
\end{enumerate}
\end{itemize}

\end{proof}

\input{figure:example:neg}

\NI We continue with a worked example of $\mathsf{neg}$.  Consider
  $y$ and $y'_j$ as in Figure \ref{figure:example:neg}.  One formula
  that is true in $y'_j$ but not in $y$ is

\[
   \langle a \rangle (\langle b \rangle \top \AND \langle c \rangle \top)
\]

\NI Now:

\begin{eqnarray*}
\lefteqn{\mathsf{neg}(y, \langle a \rangle (\langle b \rangle \top \AND \langle c \rangle \top))}\qquad \qquad \qquad  \\
& = & \bigwedge\limits_{y \xrightarrow{a} z} \langle a \rangle \mathsf{neg}(z, \langle b \rangle \top \AND \langle c \rangle \top)  \\
& = & \langle a \rangle \mathsf{neg}(z_1, \langle b \rangle \top \AND \langle c \rangle \top) \AND \langle a \rangle\mathsf{neg}(z_2, \langle b \rangle \top \AND \langle c \rangle \top)  \\
& = & \langle a \rangle (\langle b \rangle \top \AND \mathsf{neg}(z_1, \langle c \rangle \top)) \AND \langle a \rangle\mathsf{neg}(z_2, \langle b \rangle \top \AND \langle c \rangle \top)  \\
& = & \langle a \rangle (\langle b \rangle \top \AND \mathsf{neg}(z_1, \langle c \rangle \top)) \AND \langle a \rangle(\mathsf{neg}(z_2, \langle b \rangle \top) \AND \langle c \rangle \top)  \\
& = & \langle a \rangle (\langle b \rangle \top \AND \fBang \{b\}) \AND \langle a \rangle(\mathsf{neg}(z_2, \langle b \rangle \top) \AND \langle c \rangle \top)  \\
& = & \langle a \rangle (\langle b \rangle \top \AND \fBang \{b\}) \AND \langle a \rangle(\fBang \{c\} \AND \langle c \rangle \top) 
\end{eqnarray*}

\NI The resulting formula is true in $y$ but not in $y'_j$.


\subsection{Non-determinism and eremic models}

Both, eremic models and pure eremic models must be deterministic. That
is important for the incompatibility semantics. However, formally, the
definition of satisfaction makes sense for non-deterministic models as
well, pure or otherwise. Such models are important in the theory of
concurrent processes. Many of the theorems of the precious section
either hold directly, or with small modifications for
non-deterministic models. The rules of inference in Figure
\ref{figure:elAndBangRules} are sound except for
    [\RULENAME{Determinism}] which cannot hold in properly
    non-deterministic models. With this omission, they are also
    complete.  Elementary equivalence on non-deterministic eremic
    models also coincides with mutual simulation, while elementary
    equivalence on non-deterministic pure eremic models is
    bisimilarity. The proofs of both facts follow those of Theorems
    \ref{theorem:completeLattice} and \ref{hennessymilnertheorem},
    respectively. Compactness by translation can be shown following
    the proof in Section \ref{compactness}, except that the constraint
    $\phi_{det}$ is unnecessary.

We don't pursue the investigation of non-deterministic models in this
text, and leave it as future work.

\subsection{Non-deterministic eremic logic cannot express incompatibility}
\martin{Integrate with rest}

We have experimented with a version of EL in which the models are
\emph{non-deterministic} labeled-transition systems.  Although
non-determinism makes some of the constructions simpler,
non-deterministic EL is unable to express incompatibility properly.
Consider, for example, the claim that Jack is married to Jill\martin{Actually, the
formalisation below says Jack is married to Jill, and Jill only.}. 
In standard deterministic EL this would be rendered as:
\begin{eqnarray*}
\MAY{jack} \MAY{married} (\MAY{jill} \land \fBang \{jill\})
\end{eqnarray*}
There are three levels at which this claim can be denied.\martin{Jack could be a polygamist}
First, we can claim that Jack is married to someone else - Joan, say:
\begin{eqnarray*}
\MAY{jack} \MAY{married} (\MAY{joan} \land \fBang \{joan\})
\end{eqnarray*}
Second, we can claim that Jack is unmarried (specifically, that being unmarried is Jack's only property):
\begin{eqnarray*}
\MAY{jack} !\{unmarried\}
\end{eqnarray*}
Third, we can claim that Jack does not exist at all. Bob and Jill, for example, are the only people in our domain:
\begin{eqnarray*}
\fBang \{bob, jill\}
\end{eqnarray*}

Now we can assert the same sentences in non-deterministic EL, but they
are \emph{no longer incompatible with our original sentence}.  In
non-deterministic EL, the following sentences are compatible (as long
as there are two separate transitions labelled with $married$, or two
separate transitions labelled with $jack$):\martin{Maybe add a figure that shows
the relevant non-deterministic LTS?}
\begin{eqnarray*}
\MAY{jack} \MAY{married} (\MAY{jill} \land \fBang \{jill\}) \\
\MAY{jack} \MAY{married} (\MAY{joan} \land \fBang \{joan\})
\end{eqnarray*}
Similarly, the following sentences are fully compatible as long as there are two separate transitions labelled with $jack$:
\begin{eqnarray*}
\MAY{jack} \MAY{married}\\
\MAY{jack} \fBang \{unmarried\}
\end{eqnarray*}

Relatedly, non-deterministic EL does not satisfy Brandom's Incompatibility Semantics property:\martin{I don't think we have formally defined it so far. This important
concept should maybe not be introduced as a side remark.}
\[
\phi \models \psi \; \mbox{ iff } \; \mathcal{I}(\psi) \subseteq \mathcal{I}(\phi)
\]
To take a simple counter-example, $\MAY{a}\MAY{b}$ implies $\MAY{a}$, but not conversely.
But in non-deterministic EL, the set of sentences incompatible with $\MAY{a}\MAY{b}$ is identical with the set of sentences incompatible with  $\MAY{a}$.
