\section{Related Work}

\subsection{Brandom's Incompatibility Semantics}
In \cite{brandom2} and \cite{brandom}, Brandom has emphasised that logical negation is a degenerate case of material incompatibility:
\begin{quote}
Incompatible sentences are Aristotelian \emph{contraries}. A sentence and its negation are \emph{contradictories}. What is the relation between these? Well, the contradictory is a contrary: any sentence is incompatible with its negation. What distinguishes the contradictory of a sentence  from all the rest of its contraries? The contradictory is the \emph{minimal} contrary: the one that is entailed by all the rest. Thus every contrary of ``Plane figure $f$ is a circle'' - for instance ``$f$ is a triangle'', ``$f$ is an octagon'', and so on - entails ``$f$ is \emph{not} a circle''.
\end{quote}
In \cite{brandom}, Chapter 5, Appendix I, Brandom developed a new type of semantics, Incompatibility Semantics, that takes material incompatibility - rather than truth-assignment - as the semantically primitive notion.

Incompatibility Semantics applies to any language, $\mathcal{L}$, given as a set of sentences. 
It uses an incompatibility function $\mathcal{I}$, that, given a set of sentences $S \subseteq \mathcal{L}$, produces the set of sets of sentences that are incompatible with $S$.
We assume that $\mathcal{I}$ satisfies the monotonicity requirement (Brandom calls it ``Persistence''):
\[
\text{If } X \in \mathcal{I}(Y) \text{ and } X \subseteq X' \text{ then } X' \in \mathcal{I}(Y)
\]
Now Brandom defines entailment in terms of the incompatiblity function. Given a set $X \subseteq \mathcal{L}$ and an individual sentence $\phi \in \mathcal{L}$:
\[
X \models \phi \text{ iff } \mathcal{I}(\{\phi\}) \subseteq \mathcal{I}(X)
\]
Now, given material incompatibility (as captured by the $\mathcal{I}$ function) and entailment, he introduces logical negation as a \emph{derived} concept. Using $N \phi$ for the negation of $\phi$, he introduces negation via the rule:
\[
\{N \phi\} \in \mathcal{I}(X) \text{ iff } X \models \phi
\]
Brandom goes on to show that the $N$ operator, as defined, satisfies the laws of classical negation. 
He also introduces a modal operator, again defined in terms of material incompatibility, and shows that this operator satisfies the laws of $S5$.

\ELFULL{} was inspired by Brandom's vision that material incompatibility is conceptually prior to logical negation:
in other words, it is possible for a community of language users to deploy a language including a material incompatibility relation, even if that language has no explicit logical operators such as negation.
The language users of this simple language may go on to introduce logical operators, in order to make certain inferential properties explicit - but this is an optional further development. 
The language before that addition was already in order as it is.

The approach taken in this paper takes Brandom's original insight in a different direction.
While Brandom defines an unusual (non truth-conditional) semantics that applies to any language, we have defined a unusual logic with a standard (truth-conditional) semantics.






\subsection{Other Related work}

Linguists have also investigated how mutually exclusive alternatives
are expressed \cite{OKeeffeA:rouhanocl}\martin{See John C email for
  more precise reference}, but, to the best of our knowledge have not
proposed formal theories of linguistic exclusion.

\PARAGRAPH{Linear logic} Linear logic \cite{GirardJY:linlog,GirardJY:protyp} 
is a refinement of first-order logic and was introduced by
J.-Y.~Girard with the aim of bringing the symmetries of classical
logic to constructive logic. Linear logic has been fruitful in a
variety of fields, in particular in the study of typing systems, where
the concept of linearity puts type-based resource handling on a sound
logical basis.

Linear logic splits conjunction into two: additive and multiplicative
conjunction The former, additive conjunction $A \& B$, is especially
interesting in the context of \ELFULL{}. It can be interpreted
\cite{AbramskyS:comintoll} as an external choice operation in the
terminology of CSP \cite{HoareC:comseq}. External, because the choice
is offered to the environment.  This interpretation has been
influential in the study of types for process calculus,
e.g.~\cite{HondaK:unitypsfsifLONG,TakeuchiK:intbaslaits,HondaK:lanpriatdfscbp}.
Implicitly, additive conjunction gives an explicit upper bound on how
many different options the environment can choose from. For example in
$A \& B \& C$ we have three options (assuming that none of $A, B, C$
can be decomposed into further additive conjunctions).  With this in
mind, and simplifying a great deal, a key difference between $!A$ and
additive conjunction $A \& B$ is that the individual actions in $!A$
have no continuation, while they do with $A \& B$: $!\{l, r\}$ says
that at this point the only available actions are $l$ and $r$. What
happens at later states is not constraind by $!A$.  In contrast, $A \&
B$ says not only that at this point the only available options are $A$
and $B$, but also that if we choose $A$, then $A$ holds 'for ever',
and likewise for choosing $B$. To be sure, the alternatives in $A \&
B$ may themselves contain further additive conjunctions, and in this
way express how exclusion changes 'over time'.

In summary, \ELABR{} and linear logic offer an operator that restricts
the available options. How are they related? Linear logic has an
explicit linear negation $(\cdot)^{\bot}$ which, unlike classical
negation, is constructive. In constrast, \ELABR{} defines a restricted
form negation from $!A$. Can these two perspectives be frutifully
reconciled?

In this context it is also worth noting that like eremic logic, linear
logic has been used for logic programming
\cite{HodasJS:logproiafoill,WinikoffMD:logprowll,PymDJ:uniprotiollp,HarlandJ:prolygao,MillerD:surlinlp}
and as a programming language for narrative generation
\cite{BosserAG:linlogpfng}, see references therein.

\PARAGRAPH{Process calculus} Another formalism that has a form of 
explicit description of mutually exclusive option as a core primitive
are process calculi. They are models of computation based on the idea
of message passing between actors running in parallel. Labelled
transition systems are often used as models for process calculi, and
many concepts, for example bisimulations and Hennessy-Milner logic,
used for developing eremic logic originated from process theory
(although some, such as bisimulation, evolved independently in other
contexts).

Process calculi traditionally have sums, which, in their most general
form, are:
\[
     \sum_{i \in I} P_i
\]
That is a process that can internally choose, or be chosen to evolve
into the process $P_i$ for each $i$. Once the choice is made, all
other options disappear.  Usually, so much generality is not
considered. Instead, input-guarded sums are much better behaved (and
strictly less expressive):
  \[
     \sum_{i \in I} x_{i}(v_i)P_i
  \]
This is a process that can receive a message on each channel $x_i$
and, if such a message arrives with payload $y$, evolve into
$P_i{y/v_i}$ which is the process obtained from $P_i$ by substituting
$y$ for the bound variable $v_i$.  An even better behaved process is
obtained if all inputs use the same input channel and we have only
finitely many alternatives:
  \[
     \sum_{i = 1}^n x(v)P_i
  \]
  Simplifying a great deal, this can be seen as a proof for linear
  logic's additive conjunction
  \[
     \&_{i = 1}^n x(v)A_i
  \]
  provided each $P_i$ is a proof of $A_i$.  It is possible to extend
  the Curry-Howard correspondence to (fragments of) linear logic on
  one side and process calculi on the other \cite{GaySJ:typcalosp}.

In this way, process calculi are related to linear logic (by using
formulae as types) and to eremic logic (because processes and eremic
formulae can be modelled by labelled transition systems, and because
eremic logic is close to logics for processes).\martin{rephrase. How
  did process theory influence EL?}

\PARAGRAPH{Failures/divergences} Our eremic models are remarkably
close to a form of the failures/divergences models that has been used
in the denotational semantics of Hoare's CSP
\cite{HoareC:comseq,RoscoeAW:theapoc}.  In this model, the denotation
of a process $P$ is given as a pair

\[
   (tr, fail)
\]

A \emph{failure} is a pair $(\sigma, R)$ where $\sigma \in \Sigma^*$
and $R \subseteq \Sigma$. The intended interpretation is that a
process $P$ has failure $(\sigma, R)$ provided that $\sigma$ is a
trace of $P$ and after $P$ executes all the actions in $\sigma$ it
refuses to do any action given in $R$. The denotation $\SEMB{P}$ of
$P$ in a failures/divergences model is the the set of all of $P$'s
failures. The set
\[
   traces(P)
      =
   \{ \sigma\ |\ (\sigma, X) \in \SEMB{P} \}
\]
is prefix-closed, hence gives rise of a deterministic labelled
transition system.
\begin{itemize}

\item States are given by the set $traces(P)$ of all traces.

\item Transitions are of the form $\sigma \TRANS{a} \sigma.a$, where
  $\sigma.a$ is the string extending $\sigma$ with the action $a$.

\item Start state is the empty string.

\end{itemize}
We can decorate all states as follows:
\[
   \lambda (\sigma) = \Sigma \setminus R
\]
provided that $(\sigma, R) \in \SEMB{P}$.  Whenever the set $\Sigma$
of symbols is finite, we obtain an eremic model this way.

While the failures/divergences semantics of CSP are somewhat more
complicated due to the possibility of diverging programs, the close
connection between eremic logic and the denotation semantics, as well
as the syntatic similarity with Hennessy-Milner logic suggest that it
might be fruitful to investigate how eremic logic can be used as a
program logic for process calculi.

