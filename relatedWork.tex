\section{Related work}\label{relatedWork}

%% We have defined \cathoristic{}, and investigated its key properties.
%% We close with an overview of related work and a discussion of 
%% open problems.

This section surveys  \cathoristic's intellectual background, and related
approaches.


%% The work described here was inspired by Sellars' and Brandom's claim
%% that material incompatibility is conceptually prior to logical
%% negation.
%% \Cathoristic{} is a logic without negation in which you can, nevertheless, make incompatible claims.

\subsection{Brandom's incompatibility semantics}
\NI In \cite{brandom}, Chapter 5, Appendix I, Brandom developed a new
type of semantics, incompatibility semantics, that takes material
incompatibility - rather than truth-assignment - as the semantically
primitive notion.

Incompatibility semantics applies to any language, $\mathcal{L}$,
given as a set of sentences.  Given a predicate $\mathsf{Inc}(X)$
which is true of sets $X \subseteq \mathcal{L}$ that are incompatible,
he defines an incompatibility function $\mathcal{I}$ from subsets of
$\mathcal{L}$ to sets of subsets of $\mathcal{L}$:
\[
X \in \mathcal{I}(Y) \quad\text{ iff }\quad \mathsf{Inc}(X \cup Y).
\]
We assume that $\mathcal{I}$ satisfies the
monotonicity requirement (Brandom calls it ``Persistence''):
\[
   \text{If } X \in \mathcal{I}(Y) \text{ and } X \subseteq X' \text{ then } X' \in \mathcal{I}(Y).
\]

\NI Now Brandom defines entailment in terms of the incompatibility
function. Given a set $X \subseteq \mathcal{L}$ and an individual
sentence $\phi \in \mathcal{L}$:

\[
   X \models \phi\quad \text{ iff }\quad \mathcal{I}(\{\phi\}) \subseteq \mathcal{I}(X).
\]

\NI Now, given material incompatibility (as captured by the
$\mathcal{I}$ function) and entailment, he introduces logical negation
as a \emph{derived} concept via the rule:

\[
   \{\neg \phi\} \in \mathcal{I}(X)\quad \text{ iff }\quad X \models \phi.
\]

\NI Brandom goes on to show that the $\neg$ operator, as defined, satisfies
the laws of classical negation.  He also introduces a modal operator,
again defined in terms of material incompatibility, and shows that
this operator satisfies the laws of $S5$.

\Cathoristic{} was inspired by Brandom's vision that material
incompatibility is conceptually prior to logical negation: in other
words, it is possible for a community of language users to make incompatible claims, even if that
language has no explicit logical operators such as negation.  The
language users of this simple language may go on to introduce logical
operators, in order to make certain inferential properties explicit -
but this is an optional further development.  The language before that
addition was already in order as it is.

The approach taken in this paper takes Brandom's original insight in a
different direction.  While Brandom defines an unusual (non
truth-conditional) semantics that applies to any language, we have
defined an unusual logic with a standard (truth-conditional) semantics, and then shown that this logic satisfies the Brandomian connection between incompatibility and entailment.

\subsection{Peregrin on defining a negation operator}\label{peregrin}

Peregrin \cite{PeregrinJ:logbasoi} investigates the  structural
rules that any logic must satisfy if it is to connect incompatibility
($\mathsf{Inc}$) and entailment ($\models$) via the Brandomian
incompatibility semantics constraint:
\[
X \models \phi \quad\text{ iff }\quad \mathcal{I}(\{\phi\}) \subseteq \mathcal{I}(X).
\]

\NI The general structural rules are:
\begin{eqnarray*}
  (\bot) & & \text{If } \mathsf{Inc}(X) \text{ and } X \subseteq Y \text{ then } \mathsf{Inc}(Y). \\
  (\models 1) & & \phi, X \models \phi. \\
  (\models 2) & & \text{If }X, \phi \models \psi \text{ and } Y \models \phi \text{ then } X, Y \models \psi. \\
  (\bot \models 2) & & \text{If } X \models \phi \text{ for all } \phi, \text{ then } \mathsf{Inc}(X). \\
  (\models \bot 2) & & \text{If } \mathsf{Inc}(Y \cup \{\phi\}) \text{ implies } \mathsf{Inc}(Y \cup X) \text{ for all } Y, \text{ then } X \models \phi.
\end{eqnarray*}

\NI Peregrin shows that if a logic satisfied the above laws, then
incompatibility and entailment are mutually interdefinable, and the
logic satisfies the Brandomian incompatibility semantics constraint.

Next, Peregrin gives a pair of laws for defining negation in terms
of $\mathsf{Inc}$ and $\models$\footnote{The converse of $(\neg 2)$
  follows from $(\neg 1)$ and the general structural laws above.}:
\begin{eqnarray*}
  (\neg 1) & & \mathsf{Inc}(\{\phi, \neg \phi\}). \\
  (\neg 2) & & \text{If } \mathsf{Inc}(X, \phi) \text{ then } X \models \neg \phi.
\end{eqnarray*}

\NI These laws characterise intuitionistic negation as the
\emph{minimal incompatible}\footnote{$\psi$ is the minimal
  incompatible of $\phi$ iff for all $\xi$, if $\mathsf{Inc}(\{\phi\}
  \cup \{\xi\})$ then $\xi \models \psi$.}.  
  Now, in \cite{brandom},
Brandom defines negation slightly differently. He uses the rule:
\begin{eqnarray*}
  (\neg B) & &\mathsf{Inc}(X, \neg \phi) \text{ iff } X \models \phi.
\end{eqnarray*}
Using this stronger rule, we can infer the classical law of
double-negation: $\neg \neg \phi \models \phi$.  Peregrin establishes
that Brandom's rule for negation entail $(\neg 1)$ and $(\neg 2)$
above, but not conversely: Brandom's rule is stronger than Peregrin's
minimal laws $(\neg 1)$ and $(\neg 2)$.

Peregrin concludes that the Brandomian constraint between
incompatibility and entailment is satisfied by many different logics.
Brandom and Aker happened to choose a particular rule for negation
that led to classical logic, but the general connection between
incompatibility and entailment is satisfied by many different logics,
including intuitionistic logic.  This paper supports Peregrin's
conclusion: we have shown that \cathoristic{} also satisfies the
Brandomian constraint.

\subsection{Peregrin and Turbanti on defining a necessity operator}\label{peregrinTurbanti}

In \cite{brandom}, Brandom gives a rule for defining necessity in terms of incompatibility and entailment:
\[
X \in \mathcal{I}(\{\Box \phi\}) \quad\text{ iff }\quad \mathsf{Inc}(X) \lor \exists Y . \; Y \notin \mathcal{I}(X) \land Y \nvDash \phi.
\]
In other words, $X$ is incompatible with $\Box \phi$ if $X$ is compatible with something that does not entail $\phi$.

The trouble is, as Peregrin and Turbanti point out, if $\phi$ is not tautological, then \emph{every set} $X \subseteq \mathcal{L}$ is incompatible with $\Box \phi$.
To show this, take any set $X \subseteq \mathcal{L}$. 
If $\mathsf{Inc}(X)$, then $X \in \mathcal{I}(\Box \phi)$ by definition.
If, on the other hand, $\neg \mathsf{Inc}(X)$, then let $Y = \emptyset$.
Now $\neg \mathsf{Inc}(X \cup Y)$ as $Y = \emptyset$, and $Y \nvDash \phi$ as $\phi$ is not tautological.
Hence $X \in \mathcal{I}(\Box \phi)$ for all $X \subseteq \mathcal{L}$. 
Brandom's rule, then, is only capable of specifying a very specific form of necessity: logical necessity.

In \cite{PeregrinJ:logbasoi} and \cite{turbanti}, Peregrin and Turbanti describe alternative ways of defining necessity.
These alternative rule sets can be used to characterise modal logics other than S5.
For example, Turbanti defines the accessibility relation between worlds in terms of a \emph{compossibility relation}, and then argues that the S4 axiom of transitivity fails because compossibility is not transitive.

We draw two conclusions from this work.
The first is, once again, that a commitment to connecting incompatibility and entailment via the Brandomian constraint:
\[
X \models \phi\quad \text{ iff }\quad \mathcal{I}(\{\phi\}) \subseteq \mathcal{I}(X)
\]
does not commit us to any particular logical system. 
There are a variety of logics that can satisfy this constraint.
Second, questions about the structure of the accessibility relation in Kripke semantics - questions that can seem hopelessly abstract and difficult to answer - can be re-cast in terms of concrete questions about the incompatibility relation.
Incompatibility semantics can shed light on possible-world semantics \cite{turbanti}. 

\subsection{Linear logic}

Linear logic \cite{GirardJY:linlog} is a refinement of
first-order logic and was introduced by J.-Y.~Girard and
brings the symmetries of classical logic to constructive
logic. 

Linear logic splits conjunction into additive and multiplicative
parts. The former, additive conjunction $A \& B$, is especially
interesting in the context of \cathoristic{}. In the terminology of
process calculus it can be interpreted as an external choice operation
\cite{AbramskyS:comintoll}. (`External', because the choice is offered to
the environment).  This interpretation has been influential in the
study of types for process calculus,
e.g.~\cite{HondaK:unitypsfsifLONG,TakeuchiK:intbaslaits,HondaK:lanpriatdfscbp}.
Implicitly, additive conjunction gives an explicit upper bound on how
many different options the environment can choose from. For example 
$A \& B \& C$ has  three options (assuming that none of $A, B, C$
can be decomposed into further additive conjunctions).  With this in
mind, and simplifying a great deal, a key difference between $!A$ and
additive conjunction $A \& B$ is that the individual actions in $!A$
have no continuation, while they do with $A \& B$: the tantum $!\{l, r\}$ says
that the only permitted  actions are $l$ and $r$. What
happens at later states is not constrained by $!A$.  In contrast, $A \&
B$ says not only that at this point the only permissible options are $A$
and $B$, but also that if we choose $A$, then $A$ holds `for ever',
and likewise for choosing $B$. To be sure, the alternatives in $A \&
B$ may themselves contain further additive conjunctions, and in this
way express how exclusion changes 'over time'.

In summary, \cathoristic{} and linear logic offer  operators that restrict
the permissible options. How are they related? Linear logic has an
explicit linear negation $(\cdot)^{\bot}$ which, unlike classical
negation, is constructive. In contrast, \cathoristic{} defines a restricted
form of negation using $!A$. Can these two perspectives be fruitfully
reconciled?

\subsection{Process calculus}

Process calculi are models of concurrent computation.  They are based
on the idea of message passing between actors running in parallel.
Labelled transition systems are often used as models for process
calculi, and many concepts used in the development of \cathoristic{} -
for example, bisimulations and Hennessy-Milner logic - originated in
process theory (although some, such as bisimulation, evolved
independently in other contexts).

Process calculi typically feature a construct called sum, that is an
explicit description of mutually exclusive option:
\[
     \sum_{i \in I} P_i
\]
That is a process that can internally choose, or be chosen externally
by the environment to evolve into the process $P_i$ for each $i$. Once
the choice is made, all other options disappear.  Sums also relate
closely to linear logic's additive conjunction. Is this conceptual
proximity a coincidence or indicative of deeper common structure?


\subsection{Failures/divergences in process calculi}

Our cathoristic models are close to a form of the failures/divergences
models that has been used in the denotational semantics of process
calculi, primarily Hoare's CSP \cite{HoareC:comseq,RoscoeAW:theapoc}
and its descendants.  In this model, the denotation of a process $P$
is given as a pair $(traces(P), fail(P))$.
Here, $traces(P) = \{
\sigma\ |\ (\sigma, X) \in \SEMB{P} \}$ are $P$'s traces, the sequences of actions $P$ can engage in;
 $fail(P)$ is the set of failures.  
A \emph{failure} is a pair $(\sigma, R)$ where $\sigma \in
\Sigma^*$ and $R \subseteq \Sigma$. The intended interpretation is
that a process $P$ has failure $(\sigma, R)$ provided that $\sigma$ is
a trace of $P$ and after $P$ executes all the actions in $\sigma$ that  $P$
refuses to do any action given in $R$. The denotation $\SEMB{P}$ of
$P$ in a failures/divergences model is the the set of all of $P$'s
failures. The set $ traces(P)$ is prefix-closed, hence gives rise to a
deterministic labelled transition system: states are given by the set
$traces(P)$ of all traces.  Transitions are of the form $\sigma
\TRANS{a} \sigma.a$, where $\sigma.a$ is the string extending $\sigma$
with the action $a$.  The start state is the empty string.  We can
decorate all states as follows: $ \lambda (\sigma) = \Sigma \setminus
R $ provided that $(\sigma, R) \in \SEMB{P}$.  Whenever the set
$\Sigma$ of symbols is finite, we obtain a cathoristic model this
way.

While the failures/divergences semantics of CSP are somewhat more
complicated due to the possibility of diverging programs, the close
connection between cathoristic models and the denotations of CSP processes,
as well as the syntactic similarity with Hennessy-Milner logic suggest
that it is fruitful to investigate how \cathoristic{} can be used
as a program logic for process calculi.

\subsection{Linguistics}

Linguists have also investigated how mutually exclusive alternatives
are expressed, often in the context of antonymy
\cite{OKeeffeA:rouhanocl,AronoffM:hanlin,AllanK:conencos}, but, to the
best of our knowledge have not proposed formal theories of linguistic
exclusion.

