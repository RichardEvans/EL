\section{Core eremic logic: the EL$[\AND, !]$ fragment}

\subsection{Syntax}

\begin{definition} Given a set $\mathcal{S}$ of symbols, with $a$ ranging over
$\mathcal{S}$, and $A$ ranging over finite subsets of $\mathcal{S}$,
the formulae of EL$[\AND, !]$ are given by:

\begin{GRAMMAR}
  \phi 
     &\quad ::= \quad & 
  \top 
     \VERTICAL 
  \phi_1 \AND \phi_2  
     \VERTICAL 
  \MAY{a}{\phi}
     \VERTICAL 
  \fBang A 
\end{GRAMMAR}

\NI The $!$ operator is used to restrict the allowable transitions
coming out of a state.  Intuitively, $\fBang A$ means that the
\emph{only} transitions coming out of the current state are those
specified in $A$.
\end{definition}

\subsection{Semantics}

\begin{definition}
A {\bf model} is a triple $(\mathcal{W}, \rightarrow, \lambda)$,
containing a Labeled Transition System (a set of states $\mathcal{W}$,
and a transition relation $\rightarrow \; \subseteq \; \mathcal{W}
\times \mathcal{S} \times \mathcal{W}$), together with a
node-labelling $\lambda$ that maps each element of $\mathcal{W}$ to a
subset of $\mathcal{S}$.
\end{definition}
The intended interpretation is that $\lambda(w)$ is the set of allowed transition symbols emanating from $w$.
The $\lambda$ function is the semantic counterpart of the $!$ operator.

Now, for a model to be valid, we insist that the transitions coming out of a node $w$ are a subset of the allowed transitions in $\lambda(w)$:
\begin{definition}
A model $(\mathcal{W}, \rightarrow, \lambda)$ is {\bf valid} iff for all $w \in \mathcal{W}$, $ \{s \fOr \exists w' \; w \xrightarrow{s} w'\} \subseteq \lambda(w)$.
\end{definition}

\begin{definition}
A {\bf pointed model} is a pair $(l,w)$, where $m$ is a \emph{valid} model of the form $(\mathcal{W}, \rightarrow, \lambda)$, and $w$ is a distinguished state in $\mathcal{W}$.
\end{definition}
Formulae are interpreted in a pointed model $(l,w)$:
\begin{eqnarray}
(l,w) & \models & \top  \mbox{ always } \nonumber \\
(l,w) & \models & \phi_1 \AND \phi_2 \mbox{ iff } (l,w)  \models \phi_1 \mbox { and } (l,w) \models \phi_2 \nonumber \\
(l,w) & \models & \langle a \rangle \phi \mbox{ iff there is a } w \xrightarrow{a} w' \mbox { such that } (l,w') \models \phi \nonumber \\
(l,w) & \models & \fBang A \mbox{ iff } \lambda(w) \subseteq A\nonumber
\end{eqnarray}
Note that if a model is valid then $(l,w) \models \fBang A$ implies $\{s \fOr \exists w' \; w \xrightarrow{s} w'\} \subseteq A$.
From now on, we will restrict ourselves to valid models.

\input{figure:elAndBang:models}


\input{figure:elAndBangRules}

\subsection{Inference Rules}

This section presend the inference rules for EL.
In EL, a judgement is of the form:

\[
  X \judge Y
\]

\NI Here, $X$ and $Y$ are \emph{single formulae}, not sequents.  To
avoid the need for structural inference rules, we restrict sequents to
single formulae on the left and right hand side. Figure
\ref{figure:elAndBangRules} presents all rules.  EL proof rules can be
grouped in two parts: standard rules and rules unique to EL.  Standard
rules are [\RULENAME{Identity}], [\RULENAME{$\top$-Right}],
[\RULENAME{$\bot$-Left}], [\RULENAME{Transitivity}],
[\RULENAME{$\AND$-Left 1}], [\RULENAME{$\AND$-Left 2}] and
[\RULENAME{$\AND$-Right}] hardly need explanation as they are variants
of familiar rules for propositional logic, see
e.g.~\cite{TroelstraAS:basprot,vanDalenD:logstr}.  We now explain the
rules that give EL's its distinctive properties: the relations betwen
$\langle \rangle$, $!$ and $\bot$.

The rule [\RULENAME{$\bot$-Right 1}] axiom captures the core
\emph{exclusion} property of !: for example if $A = \{male, female\}$
then $\MAY{orange}{X}$ is incompatible with $!A$. Thus $!A \AND
\MAY{orange}{X}$ must be false.

The rule [\RULENAME{$\bot$-Right 2}] expresses that falsity is 'global'
  and cannot be surpressed by prefixing. For example
  $\MAY{orange}{\bot}$ is false, simply because $\bot$ is already
  false.

Relatedly, the rule [\RULENAME{Transition Normal}] enables us to
prefix an inference with a may-modality. For example \martin{add good
  example here.}. Note that it is vital for soundness that $X$ in $X
\judge Y$ is a single formula. If we used transitional sequents $X_1, ..., X_n \judge Y$,
then the rule
\[
   \ONEPREMISERULE
   {
     X_1, ..., X_n \judge Y
   }
   {
     \MAY{a}{X_1}, ..., \MAY{a}{X_n} \judge \MAY{a}{Y}
   }
\]
is unsound. \martin{explain why, and why this is significant}. This
restriction is also in place in \cite{GaySJ:typcalosp} where a
Curry-Howard corrospondence between a fragment of linear logic
\cite{GirardJY:linlog,GirardJY:protyp} and a process calculus is
introduced. We discuss the relationship between EL and linear logic in
general, and linear logic's additive conjunction in Section
\ref{conclusion}.


The three rules [\RULENAME{!-Left}, \RULENAME{!-Right 1},
  \RULENAME{!-Right 2}] jointly express of the subset relation
$\subseteq$ on sets of symbols relates to provability. Readers
familiar with object-oriented programming will recognise
[\RULENAME{!-Left}] as contra-variant subtyping and [\RULENAME{!-Right
    1}] as covariant subtyping. Honda \cite{HondaK:thetypftpc}
develops a full theory of subtyping based on similar ideas.  All three
rules embody the intuition that whenever $A \subseteq A'$ then
asserting that $!A'$ is as strong as, or a stronger statement than
$!A$. [\RULENAME{!-Left}] simply states that we can always strengthen
our premise, while [\RULENAME{!-right 1}] allows us to weaken the
premise. \martin{add an intuitive explanation for [\RULENAME{!-right 2}]!}!

Note that the logic has no axioms. One reason for a purely rule-based
presentation is the absence of implication in the present fragment of
EL. \martin{explain in more detail!}

We close this subsection with a key meta-theorem.

\begin{theorem}\label{theorem:elAndBang:soundComplete}
The rules in Figure \ref{figure:elAndBangRules} are sound and complete:
\begin{enumerate}

\item\label{theorem:elAndBang:sound} (Soundness) $X \judge Y$ implies $X \models Y$.

\item\label{theorem:elAndBang:complete} (Completeness) $X \models Y$ implies $X \judge Y$.

\end{enumerate}
\end{theorem}

\NI Soundness is immediate from the definitions. Proof of completeness is
deferred to Section \ref{completenessProof}. 

\subsection{Example inferences}

We give some example inferences that illustrate how EL is used in
practise.
\martin{Add some example assertions here, for example some of those we
  use later.}

\subsection{Proof of completeness}\label{completenessProof}

\NI We now prove completeness of the rules in Figure
\ref{figure:elAndBangRules} (Theorem
\ref{theorem:elAndBang:soundComplete}.\ref{theorem:elAndBang:complete}).
The proof requires the development of additional technology which is
useful in other contexts as well.

\begin{itemize}

\item An ordering $\leq$ on models, which enables us to speak of the
  simplest model satisfying a formula.

\item An algorithm which gives the simplest model for a formula.

\item An algorithm which gives the a formula characterising a model.

\end{itemize}

\NI We now develop these three in turn and then prove completeness.

\subsubsection{A Partial Ordering on Pointed Models}

\NI We use the notion of simulation to define a partial ordering
$\leq$ on pointed models: \martin

\begin{definition}
$(l,w) \leq (l',w')$ if there is a simulation $Z$ from $l'$ to $l$ with $(w',w) \in Z$
\end{definition}
Intuitively, $m \leq n$ if $m$ can match all the transitions of $n$ while respecting the transitions-restrictions.

To make our models into a lattice, we add a bottom element $\bot$ and stipulate that $\bot \leq m$ for all pointed models $m$.
The topmost element in the lattice is the pointed model $( (\{w\}, \{\}, \{w \mapsto \mathcal{S}\}), w)$ (for some state $w$): this is the model with no transitions and no transition restrictions.

\subsubsection{Defining $\mu$ - the Simplest Pointed Model Satisfying a Formula}
We define a function $\mu$ which, given a formula $\phi$, produces the simplest\footnote{``Simplest'' as in the least upper bound, according to $\leq$, defined in formulae of simulation.} model which satisfies $\phi$:
\begin{eqnarray}
\mu (\top) & = & ( (\{v\}, \{\}, \{v \mapsto \mathcal{S}\}), v) \nonumber \\
\mu (\fBang A) & = & ( (\{v\}, \{\}, \{v \mapsto A\}), v) \nonumber \\
\mu (\phi_1 \AND \phi_2) & = & \mu(\phi_1) \sqcap \mu(\phi_2) \nonumber \\
\mu (\langle a \rangle \phi) & = & ( (\mathcal{W} \cup \{w'\}, \rightarrow \cup (w' \xrightarrow{a} w), \lambda \cup \{w' \mapsto \mathcal{S}\}]), w') \nonumber \\
		& & \mbox{where }\mu(\phi) = ( (\mathcal{W}, \rightarrow, \lambda), w) \nonumber \\
		& & \mbox{and }w' \mbox{ is a new state not appearing in }\mathcal{W} \nonumber
\end{eqnarray}
The only complex case is the clause for $\mu (\phi_1 \AND \phi_2)$, which uses the $\sqcap$ function, defined as\footnote{We assume that the sets of states in the two pointed models are disjoint.}:

\begin{eqnarray*}
  \bot \sqcap X 
     & = & 
  \bot \nonumber 
     \\
  X \sqcap \bot 
     & = & 
  \bot \nonumber 
     \\
  m \sqcap n 
     & = & 
  \begin{cases}
    \mathsf{merge}(m, n) & \text{if}\ \mathsf{consistent}(m, n) \\
    \bot & \text{else}
  \end{cases}
\end{eqnarray*}

\noindent The $\mathsf{consistent}$ predicate is true of pointed models $m$ and $n$ if the out-transitions on $m$'s root node respect the labelling on $n$'s root node, and the out-transitions on $n$'s root node respect the labelling on $m$'s root node. In other words:
\begin{eqnarray}
\mathsf{consistent}(m, n) & \mbox{ iff } & \mathsf{out}(m) \subseteq \mathsf{restriction}(n) \mbox{ and} \nonumber \\
& & \mathsf{out}(n) \subseteq \mathsf{restriction}(m) \nonumber
\end{eqnarray}
where:
\begin{eqnarray}
\mathsf{out}(((\mathcal{W},\rightarrow,\lambda),w)) & = & \{ s \fOr \exists x . w \xrightarrow{s} x \} \nonumber \\
\mathsf{restriction}(((\mathcal{W},\rightarrow,\lambda),w)) & = & \lambda(w) \nonumber
\end{eqnarray}
Now the $\mathsf{merge}$ function fuses two pointed models together:
\[
\mathsf{merge}( ( (\mathcal{W}, \rightarrow, \lambda), w),  ( (\mathcal{W}', \rightarrow', \lambda'), w')) = ((\mathcal{W} \cup \mathcal{W}', \rightarrow \cup \rightarrow'_2, \lambda_2 \cup \lambda'_2), w)
\]
where:
\begin{eqnarray}
\rightarrow'_2 & = & \rightarrow' \mbox{ with } w' \mbox{ replaced by } w \nonumber \\
\lambda_2 & = & \lambda \mbox{ with } w \mapsto \lambda(w) \cap \lambda'(w') \nonumber \\
\lambda'_2 & = & \lambda' \mbox{ with } w' \mbox{ removed } \nonumber
\end{eqnarray}
It is easy to show that $\mu$ satisfies the following propositions:
\begin{eqnarray}
\mu(\phi) & \models & \phi \nonumber \\
\mbox{if }n \models \phi \mbox{ and } m \leq n & \mbox{ then } & m \models \phi \nonumber
\end{eqnarray}

\subsubsection{Defining $\theta$ - a Formula that Characterises a Model}
The inverse function $\theta$ produces a formula that characterises a given pointed model:
\begin{eqnarray}
\theta(\bot) & = & \langle a \rangle \top \AND ! \{ \} \mbox{ for some symbol }a \nonumber \\
\theta(l, w) & = & \mathsf{bang}(l,w) \AND \bigwedge_{(s,w') \in \mathsf{trans}(l,w)} \langle s \rangle \theta(l, w') \nonumber 
\end{eqnarray}
Here:
\begin{eqnarray}
\mathsf{bang}((\mathcal{W},\rightarrow,\lambda),w) & = & \top \mbox{ if } \lambda(w) = \mathcal{S} \nonumber \\
\mathsf{bang}((\mathcal{W},\rightarrow,\lambda),w) & = & ! \; \lambda(w) \mbox{ otherwise } \nonumber \\
\mathsf{trans}((\mathcal{W},\rightarrow, \lambda),w) & = & \{(s,w') | w \xrightarrow{s} w' \} \nonumber
\end{eqnarray}
Note that $\theta(m)$ is finite if $m$ contains no cycles and if $\lambda(x)$ is either $\mathcal{S}$ or finite for all states $x$.
Note also that $\mu$ and $\theta$ are inverses of each other in that:
\begin{eqnarray}
\mu(\theta(m)) & = & m \nonumber \\
\theta(\mu(p)) & \mbox{ iff } & p \nonumber
\end{eqnarray}


We will show that $p \models q$ implies there is a derivation of $p
\judge q$.  Our proof will make use of two lemmas:
\begin{itemize}
\item
Lemma 4: if $m \models p$ then $\theta(m) \judge p$.
\item
Lemma 5: for all formulae $p$, $p \judge \theta(\mu(p))$.
\end{itemize}
With these two lemmas in hand, the proof is straightforward.
\begin{theorem}
If $p \models q$ then $p \judge q$
\end{theorem}
\begin{proof}
Assume $p \models q$. 
Then all models which satisfy $p$ also satisfy $q$.
In particular, $\mu(p) \models q$.
Then $\theta(\mu(p)) \judge q$ by Lemma 1.
But we also have, by Lemma 2, $p \judge \theta(\mu(p)) $.
So by transitivity, we have $p \judge q$.
\qed
\end{proof}
Next we will prove Lemma 4.
\begin{lemma}
If $m \models p$ then $\theta(m) \judge p$.
\end{lemma}
\begin{proof}
Induction on $p$.
\setcounter{mycase}{0}

\begin{mycase}
$p$ is $\top$
\end{mycase}
Then we can prove  $\theta(m) \judge p$ immediately using axiom {\bf $\top$ Right}.

\begin{mycase}
$p$ is $q \AND q'$
\end{mycase}
By the induction hypothesis, $\theta(m) \judge q$ and $\theta(m) \judge q'$.
The proof of $\theta(m) \judge q \AND q'$ follows immediately using {\bf $\AND$ Right}.

\begin{mycase}
$p$ is $\langle a \rangle q$
\end{mycase}
If $m \models \langle a \rangle q$, then either $m = \bot$ or $m$ is a pointed model of the form $(l,w)$.
\begin{subcase}
$m = \bot$
\end{subcase}
In this case, $\theta(m) = \theta(\bot) = \bot$. (Recall, that we are overloading $\bot$ to mean both the pointed model at the bottom of our lattice and a formula (such as $\langle s \rangle \top \AND !\{\}$) which is always false).
In this case, $ \theta(\bot) \judge  \langle a \rangle q$ using {\bf $\bot$ Left}.

\begin{subcase}
 $m$ is a pointed model of the form $(l,w)$
 \end{subcase}
Given $m \models \langle a \rangle q$, and that $m$ is a pointed model of the form $(l,w)$, we know that:
\[
(l,w) \models \langle a \rangle q
\]
From the satisfaction clause for $\langle a \rangle$, it follows that:
\[
\exists w' \mbox{ such that } w \xrightarrow{a} w' \mbox { and } (l,w') \models q
\]
By the induction hypothesis:
\[
\theta( (l,w') ) \judge q
\]
Now by {\bf Transition Normal}:
\[
\langle a \rangle \theta( (l,w') ) \judge \langle a \rangle q
\]
Using repeated application of {\bf $\AND$ Left}, we can show:
\[
\theta((l,w)) \judge \langle a \rangle \theta((l,w'))
\]
Finally, using {\bf Transitivity}, we derive:
\[
\theta((l,w)) \judge  \langle a \rangle q
\]
\begin{mycase}
$p$ is $\fBang q$
\end{mycase}
If $(l,w) \models \fBang A$, then $\lambda(w) \subseteq A$.
Then $\theta(l,w) = ! \; \lambda(w) \AND \phi$.
Now we can prove $! \; \lambda(w) \AND \phi \judge \fBang A$ using  {\bf $!$ Right 1} and repeated applications of {\bf $\AND$ Left}.
\qed
\end{proof}

\begin{lemma}
For all formulae $p$, we can derive $p \judge \theta(\mu(p))$.
\end{lemma}
Explanation: $\mu(p)$ is the simplest model satisfying $p$, and $\theta(m)$ is the simplest formula describing $m$, so $\theta(\mu(p))$ is a simplified form of $p$. This lemma states that EL has the inferential capacity to transform any proposition into its simplified form.
\begin{proof}
Induction on $p$.

\setcounter{mycase}{0}

\begin{mycase}
$p$ is $\top$
\end{mycase}
Then we can prove  $\top \judge \top$ using either {\bf $\top$ Right} or {\bf Identity}.

\begin{mycase}
$p$ is $q \AND q'$
\end{mycase}
By the induction hypothesis, $q \judge \theta(\mu(q))$ and $q' \judge \theta(\mu(q'))$.
Using {\bf $\AND$ Left} and {\bf $\AND$ Right}, we can show:
\[
q \AND q' \judge \theta(\mu(q)) \AND \theta(\mu(q'))
\]
Lemma 6, proven below, states that, for all models $m$ and $n$:
\[
\theta(m) \AND \theta(n) \judge \theta (m \sqcap n)
\]
From Lemma 6 (substituting $\mu(q)$ for $m$ and $\mu(q')$ for $n$), it follows that:
\[
\theta(\mu(q)) \AND \theta(\mu(q')) \judge \theta(\mu(q \AND q'))
\]
Our desired result follows using {\bf Transitivity}.

\begin{mycase}
$p$ is $\langle a \rangle q$
\end{mycase}
By the induction hypothesis, $q \judge \theta(\mu(q))$.
Now there are two sub-cases to consider, depending on whether or not $\theta(\mu(q)) = \bot$.
\begin{subcase}
$\theta(\mu(q)) = \bot$
\end{subcase}
In this case, $\theta(\mu(\langle a \rangle q))$ also equals $\bot$. 
By the induction hypothesis:
\[
q \judge \bot
\]
By {\bf Transition Normal}:
\[
\langle a \rangle q \judge \langle a \rangle \bot
\]
By {\bf Bottom Right 2}:
\[
\langle a \rangle \bot \judge \bot
\]
The desired proof that:
\[
\langle a \rangle q \judge \bot
\]
follows by {\bf Transitivity}.
\begin{subcase}
$\theta(\mu(q)) \neq \bot$
\end{subcase}
By the induction hypothesis, $q \judge \theta(\mu(q))$.
So, by {\bf Transition Normal}:
\[
\langle a \rangle q \judge \langle a \rangle \theta(\mu(q))
\]
The desired conclusion follows from noting that:
\[
 \langle a \rangle \theta(\mu(q)) = \theta(\mu(\langle a \rangle q))
 \]
 \begin{mycase}
$p$ is $\fBang A$
\end{mycase}
If $p$ is $\fBang A$, then $ \theta(\mu(p))$ is $\fBang A \AND \top$.
We can prove $\fBang A \judge \fBang A \AND \top$ using {\bf $\AND$ Right}, {\bf $\top$ Right} and {\bf Identity}.
\qed
\end{proof}
Finally, to fill the hole in Case 2 above, we need to show that:
\begin{lemma}
For all models $m$ and $n$, $\theta(m) \AND \theta(n) \judge \theta (m \sqcap n)$.
\end{lemma}

\begin{proof}

There are two cases to consider, depending on whether or not $(m \sqcap n) = \bot$.

\setcounter{mycase}{0}

\begin{mycase}
$(m \sqcap n) = \bot$
\end{mycase}
If $(m \sqcap n) = \bot$, there are three possibilities:
\begin{itemize}
\item
$m = \bot$
\item
$n = \bot$
\item
Neither $m$ nor $n$ are $\bot$, but together they are incompatible. 
\end{itemize}
If either $m$ or $n$ is $\bot$, then the proof is a simple application of {\bf Identity} followed by {\bf $\AND$ Left}.

Next, let us consider the case where neither $m$ nor $n$ are $\bot$, but together they are incompatible.
Let $m$ be the pointed model $(l, w)$ and let $n$ be $(l', w')$.
If $(l, w) \sqcap (l', w') = \bot$, then\footnote{The alternative, in which the $s$-transition is in $n$ and the transition-restriction is in $m$, is identical, swapping $m$ with $n$.} there exists a symbol $s$ and a state $w_2$ such that $w \xrightarrow{s} w_2$ but $s \notin \lambda'(w')$.

In this case, by the definition of $\theta$, $\theta(m) \judge \langle s \rangle \top$, using  {\bf Identity} and repeated applications of {\bf $\AND$ Left}.
Further, by the definition of $\theta$, $\theta(n) \judge \; ! \; \lambda'(w')$, using  {\bf Identity} and repeated applications of by {\bf $\AND$ Left}. Again, $s \notin  \lambda'(w')$.

Therefore,  $\theta(m) \AND \theta(n) \judge \bot$, using  {\bf $\AND$ Right} and  {\bf Bottom Right 1}.
\begin{mycase}
$(m \sqcap n) \neq \bot$
\end{mycase}
In this case, let $(l,w) = m$ and let $(l',w')=n$.
Then, from the definition of $\mathsf{merge}$ above:
\[
\theta((l,w) \sqcap (l',w')) = \; ! \; (\lambda(w) \cap \lambda'(w')) \AND \bigwedge_{w \xrightarrow{s} w_2} \langle s \rangle \theta((l, w_2)) \AND \bigwedge_{w' \xrightarrow{s} w_3} \langle s \rangle \theta((l', w_3))
\]
We need to show that $\theta((l,w)) \AND \theta((l',w')) \judge \theta((l,w) \sqcap (l',w'))$ - or in other words, that:
\begin{itemize}
\item
$\theta((l,w)) \AND \theta((l',w')) \judge \; ! \; (\lambda(w) \cap \lambda'(w'))$
\item
$\theta((l,w)) \AND \theta((l',w')) \judge \langle s \rangle \theta((l, w_2))$ for all $s,w_2$ such that $w \xrightarrow{s} w_2$
\item
$\theta((l,w)) \AND \theta((l',w')) \judge \langle s \rangle \theta((l, w_3))$ for all $s,w_3$ such that $w' \xrightarrow{s} w_3$
\end{itemize}
To show $\theta((l,w)) \AND \theta((l',w')) \judge \; ! \; (\lambda(w) \cap \lambda'(w'))$, note that $\theta((l,w))  \judge \; ! \; \lambda(w)$ and $\theta((l',w')) \judge \; ! \;  \lambda'(w'))$.
We can derive $\theta((l,w)) \AND \theta((l',w')) \judge \; ! \; (\lambda(w) \cap \lambda'(w'))$ using {\bf $\AND$ Right} and {\bf $!$ Right 2}. 

To show $\theta((l,w)) \AND \theta((l',w')) \judge \langle s \rangle \theta((l, w_2))$, observe from the definition of $\theta$ that $\theta((l,w))$ contains a conjunct $\langle s \rangle \theta((l, w_2))$, so the proof follows from  {\bf $\AND$ Right} and repeated applications of  {\bf $\AND$ Left}. The same procedure applies to show $\theta((l,w)) \AND \theta((l',w')) \judge \langle s \rangle \theta((l, w_3))$ for all $s,w_3$ such that $w' \xrightarrow{s} w_3$.

This completes Lemma 6 and hence the Completeness Proof.
\qed

\end{proof}

\subsection{The standard translation from  EL into FOL}

We will translate EL into a restricted fragment of FOL.
There are three types of predicate:
\begin{itemize}
\item
A 0-place predicate $\top$, which is true in all models.
\item
A set of two-place predicates $Arr_s(x, y)$, one for each $s \in \mathcal{S}$, where $x$ and $y$ are of type $State$. $Arr_s(x, y)$ is true if $x \xrightarrow{s} y$.
\item
A set of one-place predicates $Restrict_A$, one for each finite subset $A \subseteq \mathcal{S}$. 
$Restrict_{A}(x)$ is true if $\lambda(x) = A$.
\end{itemize}
With $x_1, x_2$ being state variables, $s$ a symbol in $\mathcal{S}$, and $A$ ranging over subsets of $\mathcal{S}$, our restricted fragment of FOL has formulae of the form:
\begin{GRAMMAR}
  \phi 
     &\quad ::= \quad&
  \top \fOr Arr_{s}(x_1, x_2)\fOr Restrict_A(x_1) \fOr \phi_1 \AND \phi_2 \fOr \exists x_1 . \phi 
\end{GRAMMAR}
Notice that this fragment of FOL has no negation, disjunction, implication, or universal quantification.

The translation of an EL formula is relative to a variable $x$ (which will be instantiated to the particular state at which we are evaluating the formula):
\begin{eqnarray}
T_x(\top) & = & \top \nonumber \\
T_x(\phi_1 \AND \phi_2) & = & T_x(\phi_1) \AND T_x(\phi_2) \nonumber \\
T_x(\langle s \rangle \phi) & = & \exists y \; . \; Arr_s(x,y) \AND T_y(\phi) \nonumber \\
T_x(\fBang A) & = & Restrict_A(x) \nonumber
\end{eqnarray}
So, for example:
\[
T_x(\langle a \rangle \top \AND \fBang \{a\}) = \exists y \; . \; Arr_a(x,y) \AND \top \AND Restrict_{\{a\}}(x)
\]


\subsection{Compactness}

